{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review notebook: harvest senses with provenance\n",
    "\n",
    "Notebook for reviewing functions\n",
    "\n",
    "- `get_provenance_by_semantic_class`\n",
    "- `extend_from_saved_lemma_query`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions assume:\n",
    "    - a pickled dataframe with information harvested\n",
    "\n",
    "What these functions should do:\n",
    "    - for a given lemma id (e.g. lemm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1-dataframe\u001b[m\r\n",
      "  19-machine-tagger\u001b[m\r\n",
      "  3-group-senses\u001b[m\r\n",
      "* \u001b[32m4-semantic-provenance\u001b[m\r\n",
      "  dev\u001b[m\r\n",
      "  master\u001b[m\r\n",
      "  oed-experiments\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_download import *\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path, PosixPath\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load credentials, set paths and arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import API credentials\n",
    "with open('oed_experiments/oed_credentials.json') as f:\n",
    "    auth = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define lemma\n",
    "lemma_id = \"machine_nn01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = Path(dp)\n",
    "save_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end = 1750,1950\n",
    "lemma_id = 'machine_nn01'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get all sense for the lemma machine_nn01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323fd9a05b514b8c931143522c8fbdea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get all synonyms of the senses listed in machine_nn01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bab928373b4d4b9f81671c2c0786fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=26.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Get all branches for seed senses and synonyms\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def8e7e4913f428aa265beb87de85c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=190.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extended_df = extend_from_saved_lemma_query(auth,lemma_id,start,end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>daterange</th>\n",
       "      <th>definition</th>\n",
       "      <th>first_use</th>\n",
       "      <th>id</th>\n",
       "      <th>lemma</th>\n",
       "      <th>main_current_sense</th>\n",
       "      <th>meta</th>\n",
       "      <th>notes</th>\n",
       "      <th>oed_reference</th>\n",
       "      <th>oed_url</th>\n",
       "      <th>part_of_speech</th>\n",
       "      <th>provenance</th>\n",
       "      <th>provenance_type</th>\n",
       "      <th>quotation_ids</th>\n",
       "      <th>semantic_class_ids</th>\n",
       "      <th>semantic_class_last_id</th>\n",
       "      <th>transitivity</th>\n",
       "      <th>word_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{'topic': [], 'usage': [['rare']], 'region': []}</td>\n",
       "      <td>{'end': None, 'start': 1545, 'obsolete': False...</td>\n",
       "      <td>A material or immaterial structure, esp. the f...</td>\n",
       "      <td>J. Schäfer</td>\n",
       "      <td>machine_nn01-38473945</td>\n",
       "      <td>machine</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created': 1904, 'revised': True, 'updated': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>machine, n., sense I.1a</td>\n",
       "      <td>https://www.oed.com/view/Entry/111850#eid38473945</td>\n",
       "      <td>NN</td>\n",
       "      <td>[[machine_nn01-38473945, seed, machine_nn01]]</td>\n",
       "      <td>seed</td>\n",
       "      <td>[machine_nn01-38473950, machine_nn01-38473961,...</td>\n",
       "      <td>[[1, 111290, 118635, 119024, 120162, 120172], ...</td>\n",
       "      <td>[120172, 120173]</td>\n",
       "      <td>None</td>\n",
       "      <td>machine_nn01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{'topic': [['Military', 'Weaponry']], 'usage':...</td>\n",
       "      <td>{'end': None, 'start': 1583, 'obsolete': False...</td>\n",
       "      <td>A military engine or siege-tower. Cf. war mach...</td>\n",
       "      <td>Brian Melbancke</td>\n",
       "      <td>machine_nn01-38474233</td>\n",
       "      <td>machine</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created': 1904, 'revised': True, 'updated': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>machine, n., sense II.3</td>\n",
       "      <td>https://www.oed.com/view/Entry/111850#eid38474233</td>\n",
       "      <td>NN</td>\n",
       "      <td>[[machine_nn01-38474233, seed, machine_nn01]]</td>\n",
       "      <td>seed</td>\n",
       "      <td>[machine_nn01-38474243, machine_nn01-38474252,...</td>\n",
       "      <td>[[153072, 160439, 163207, 163208, 163377, 1633...</td>\n",
       "      <td>[163378]</td>\n",
       "      <td>None</td>\n",
       "      <td>machine_nn01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>{'topic': [], 'usage': [], 'region': []}</td>\n",
       "      <td>{'end': 1707, 'start': 1595, 'obsolete': True,...</td>\n",
       "      <td>spec. A scheme or plot. Obsolete.</td>\n",
       "      <td>Elizabeth I</td>\n",
       "      <td>machine_nn01-38474097</td>\n",
       "      <td>machine</td>\n",
       "      <td>False</td>\n",
       "      <td>{'created': 1904, 'revised': True, 'updated': ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>machine, n., sense I.1b</td>\n",
       "      <td>https://www.oed.com/view/Entry/111850#eid38474097</td>\n",
       "      <td>NN</td>\n",
       "      <td>[[machine_nn01-38474097, seed, machine_nn01]]</td>\n",
       "      <td>seed</td>\n",
       "      <td>[machine_nn01-38474102, machine_nn01-38474122,...</td>\n",
       "      <td>[[1, 84689, 87987, 87988, 87989, 88083, 88109,...</td>\n",
       "      <td>[88126]</td>\n",
       "      <td>None</td>\n",
       "      <td>machine_nn01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          categories  \\\n",
       "0   {'topic': [], 'usage': [['rare']], 'region': []}   \n",
       "1  {'topic': [['Military', 'Weaponry']], 'usage':...   \n",
       "2           {'topic': [], 'usage': [], 'region': []}   \n",
       "\n",
       "                                           daterange  \\\n",
       "0  {'end': None, 'start': 1545, 'obsolete': False...   \n",
       "1  {'end': None, 'start': 1583, 'obsolete': False...   \n",
       "2  {'end': 1707, 'start': 1595, 'obsolete': True,...   \n",
       "\n",
       "                                          definition        first_use  \\\n",
       "0  A material or immaterial structure, esp. the f...       J. Schäfer   \n",
       "1  A military engine or siege-tower. Cf. war mach...  Brian Melbancke   \n",
       "2                  spec. A scheme or plot. Obsolete.      Elizabeth I   \n",
       "\n",
       "                      id    lemma  main_current_sense  \\\n",
       "0  machine_nn01-38473945  machine               False   \n",
       "1  machine_nn01-38474233  machine               False   \n",
       "2  machine_nn01-38474097  machine               False   \n",
       "\n",
       "                                                meta notes  \\\n",
       "0  {'created': 1904, 'revised': True, 'updated': ...    []   \n",
       "1  {'created': 1904, 'revised': True, 'updated': ...    []   \n",
       "2  {'created': 1904, 'revised': True, 'updated': ...    []   \n",
       "\n",
       "             oed_reference                                            oed_url  \\\n",
       "0  machine, n., sense I.1a  https://www.oed.com/view/Entry/111850#eid38473945   \n",
       "1  machine, n., sense II.3  https://www.oed.com/view/Entry/111850#eid38474233   \n",
       "2  machine, n., sense I.1b  https://www.oed.com/view/Entry/111850#eid38474097   \n",
       "\n",
       "  part_of_speech                                     provenance  \\\n",
       "0             NN  [[machine_nn01-38473945, seed, machine_nn01]]   \n",
       "1             NN  [[machine_nn01-38474233, seed, machine_nn01]]   \n",
       "2             NN  [[machine_nn01-38474097, seed, machine_nn01]]   \n",
       "\n",
       "  provenance_type                                      quotation_ids  \\\n",
       "0            seed  [machine_nn01-38473950, machine_nn01-38473961,...   \n",
       "1            seed  [machine_nn01-38474243, machine_nn01-38474252,...   \n",
       "2            seed  [machine_nn01-38474102, machine_nn01-38474122,...   \n",
       "\n",
       "                                  semantic_class_ids semantic_class_last_id  \\\n",
       "0  [[1, 111290, 118635, 119024, 120162, 120172], ...       [120172, 120173]   \n",
       "1  [[153072, 160439, 163207, 163208, 163377, 1633...               [163378]   \n",
       "2  [[1, 84689, 87987, 87988, 87989, 88083, 88109,...                [88126]   \n",
       "\n",
       "  transitivity       word_id  \n",
       "0         None  machine_nn01  \n",
       "1         None  machine_nn01  \n",
       "2         None  machine_nn01  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8383, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_provenance_by_semantic_class(row):\n",
    "    \"\"\"\n",
    "    decide on the relation between the sense and the target querry\n",
    "    here we use the lowest semantic class id to decide on the relation\n",
    "    \n",
    "    if last semantic class id (sc_ids[-1]) == provenance id: then sense is sibling of provenance id\n",
    "    elif provenance semantic class id in the list of semantic class last ids\n",
    "    (but provenance not the last one): then sense is descendant of provenance id\n",
    "    Argument:\n",
    "        row (pd.Series): row of dataframe obtained from branchsenses endpoint\n",
    "    \n",
    "    Returns:\n",
    "        nested listed in the format of [lowest semantic class id, relation, provenance semantic class id]\n",
    "            in other words it said that for a given sense (which can have multiple semantic class ids)\n",
    "            the lowest semantic class id stands in the relation \"sibling\" or \"descendant\" of the \n",
    "            provenance semantic class id\n",
    "    \"\"\"\n",
    "    \n",
    "    provenance = []\n",
    "    \n",
    "    for sc_ids in row.semantic_class_ids:\n",
    "        relation = ''\n",
    "        \n",
    "        # scenario 1\n",
    "        if sc_ids[-1] == row.provenance_pivot:\n",
    "            relation = 'sibling'\n",
    "        \n",
    "        # scenario 2\n",
    "        elif (row.provenance_pivot in sc_ids):\n",
    "            relation = 'descendant'\n",
    "        \n",
    "        # exclude other relation\n",
    "        if relation:\n",
    "            provenance.append([sc_ids[-1], relation, row.provenance_pivot])\n",
    "    \n",
    "    if not provenance:\n",
    "        print(f'No descendants or siblings found for {row.id}')\n",
    " \n",
    "    return provenance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get last element in a nested list\n",
    "get_last_id = lambda nested_list :[l[-1] for l in nested_list]\n",
    "    \n",
    "# load seed query dataframe\n",
    "query_df = pd.read_pickle(f\"./data/senses_{lemma_id}.pickle\")\n",
    "    \n",
    "# use the sense endpoint to ensure all information \n",
    "# can be properly concatenated in one dataframe\n",
    "    \n",
    "# retrieve all sense ids\n",
    "query_sense_ids = query_df.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all senses by sense id\n",
    "print(f\"Get all sense for the lemma {lemma_id}\")\n",
    "seeds = [(s,query_oed(auth,'sense',s,\n",
    "                flags=f\"current_in='{start}-{end}'&limit=1000\", # probably \"current_in\" not needed here see APi\n",
    "                verbose=False)) # set verbose to True to see the url request\n",
    "                    for s in tqdm(query_sense_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "seeds_df = pd.DataFrame([seed['data'] for s_id,seed in seeds])\n",
    "\n",
    "# seed_df contains all the senses of the word machine_nn01\n",
    "# we distinguish between provenance and provenance_type\n",
    "# provenance will refer to specific word, sense of semantic class ids\n",
    "# provenance_type will distinguish between different types of extension\n",
    "# define provenance, these words are \"seed\"\n",
    "seeds_df['provenance'] = [[[i,'seed',lemma_id]] for i in seeds_df.id] # for the seed sense we use the id of the word machine_nn0\n",
    "                                       # we use list here, reason is explained later, see provenance of synonyms\n",
    "seeds_df['provenance_type'] = 'seed' # categorize these lemmas as seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all synonyms for the seed senses\n",
    "# reminder synonyms uses same function as the /senses/ endpoint, flags should work here\n",
    "print(f\"Get all synonyms of the senses listed in {lemma_id}\")\n",
    "synonyms = [(s,query_oed(auth,'sense',s,\n",
    "                level='synonyms',\n",
    "                flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                        for s in tqdm(query_sense_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform list of synonyms to a dataframe\n",
    "synonyms_df = pd.DataFrame([s for s_id,syn in synonyms for s in syn['data']])\n",
    "    \n",
    "# for synonyms the provenance_type is set to \"synonym\"\n",
    "synonyms_df['provenance_type'] = 'synonym'\n",
    "# for synonyms we refer the sense_id via which this synonym was retrieved\n",
    "synonyms_df['provenance'] = [[[s['id'],'synonym',s_id]] for s_id,syn in synonyms for s in syn['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed + synonyms constitute the nucleas of our query\n",
    "# these are saved in the core_df\n",
    "# shape should be 485 (synonyms senses) + 26 (seed senses)\n",
    "core_df = pd.concat([seeds_df,synonyms_df],sort=True)\n",
    "    \n",
    "# branch out from there\n",
    "# we save the lowest level of the semantic_class_last_id columns\n",
    "core_df['semantic_class_last_id'] = core_df['semantic_class_ids'].apply(get_last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all the _lowest_ (or last) semantic class ids for the core senses so far\n",
    "semantic_class_ids = set([s for l in core_df.semantic_class_last_id.to_list() for s in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we use the descendants endpoint\n",
    "# for each lowest semantic class id\n",
    "# we get all \"descendants\" which according the API documentation\n",
    "# returns an array of senses that belong to the semantic class\n",
    "# specified by ID, plus senses that belong to its child and descendant classes.\n",
    "print(\"Get all branches for seed senses and synonyms\")\n",
    "branches = [(idx,query_oed(auth,'semanticclass', idx, \n",
    "                        level='branchsenses', # \n",
    "                        flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                            for idx in tqdm(semantic_class_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert API response to dataframe\n",
    "branches_df = pd.DataFrame([s for idx,branch in branches for s in branch['data']])\n",
    "    \n",
    "# ISSUE: again we have duplicate \n",
    "# senses here, as some appear multiple time as\n",
    "# in the same semantic class (or as descendant)\n",
    "    \n",
    "# provenance_type is branch with semantic class id \n",
    "# that was use for retrieving the sense is the provenance\n",
    "branches_df['provenance_type'] = 'branch'\n",
    "    \n",
    "# we create a provenance_pivot columsn, which shows\n",
    "# the semantic class id via which the sense was retrieved\n",
    "branches_df['provenance_pivot'] = [idx for idx, branch in branches for s in branch['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now there are two scenarios to specify for the pro\n",
    "# both scenarios can apply to one sense\n",
    "# if last semantic class id (sc_ids[-1]) == provenance id: then sense is sibling of provenance id\n",
    "# elif provenance semantic class id in the list of semantic class last ids\n",
    "# (but provenance not the last one): then sense is descendant of provenance id\n",
    "    \n",
    "branches_df['provenance'] = branches_df.apply(get_provenance_by_semantic_class,axis=1)\n",
    "    \n",
    "# drop the provenance_pivot column\n",
    "branches_df.drop('provenance_pivot',axis=1,inplace=True)\n",
    "    \n",
    "# concatenate core and branch senses\n",
    "# ISSUE: have a closer look at the warning message\n",
    "extended_df = pd.concat([core_df,branches_df],sort=True)\n",
    "\n",
    "# to check if rows match\n",
    "#extended_df.shape[0] == core_df.shape[0] + branches_df.shape[0]\n",
    "# save dataframe as pickle\n",
    "extended_df.to_pickle(f\"./data/extended_{lemma_id}.pickle\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get machine_nn01 senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query the API and get the json response\n",
    "sense_json = query_oed(credentials,'word',lemma_id,flags='include_senses=true&include_quotations=true')\n",
    "\n",
    "# convert the json in a dataframe\n",
    "senses_df = convert_json_to_dataframe(sense_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe\n",
    "# as pickle\n",
    "senses_df.to_pickle(save_path / f\"senses_{lemma_id}.pickle\")\n",
    "# as csv\n",
    "senses_df.to_csv(save_path / f\"senses_{lemma_id}.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open pickle file to avoid calling the API again\n",
    "# with open(save_path / f\"senses_{lemma_id}.pickle\",'rb') as in_pickle:\n",
    "#     machine_senses_df = pickle.load(in_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all senses that are siblings and descendants\n",
    "# # of the semantic class of senses listed in previously obtained query \n",
    "# responses = traverse_thesaurus(credentials,machine_senses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # traverse tree or load responses \n",
    "# # responses = traverse_thesaurus(credentials,machine_senses_df)\n",
    "# with open(f'{dp}/tree_traversal.pickle','rb') as in_pickle:\n",
    "#     responses = pickle.load(in_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get all quoations for the senses in the responses variable\n",
    "# quotations = get_quotations_from_thesaurus(credentials,responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge and save all information stored in the seperate pickle files\n",
    "# df = merge_pickled(Path(\"./data/senses_machine_nn01.pickle\"),\n",
    "#                    Path(\"./data/tree_traversal.pickle\"),\n",
    "#                    Path(\"./data/tree_traversal_quotations.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(f\"{dp}/{lemma_id}_all.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_pickle(f\"{dp}/{lemma_id}_all.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start,end = 1750,1950\n",
    "lemma_id = 'machine_nn01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_id = lambda nested_list :[l[-1] for l in nested_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = pd.read_pickle(f\"./data/senses_{lemma_id}.pickle\")\n",
    "    \n",
    "# use the sense endpoint to ensure all information \n",
    "# can be properly concatenated in one dataframe\n",
    "    \n",
    "# retrieve all sense ids\n",
    "query_sense_ids = query_df.id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_sense_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = credentials# for code checking, remove later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Get all sense for the lemma {lemma_id}\")\n",
    "seeds = [(s,query_oed(auth,'sense',s,\n",
    "                    flags=f\"current_in='{start}-{end}'&limit=1000\", # probably \"current_in\" not needed here see APi\n",
    "                      verbose=False)) # set verbose to True to see the url request\n",
    "                        for s in tqdm(query_sense_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dataframe\n",
    "seeds_df = pd.DataFrame([seed['data'] for s_id,seed in seeds])\n",
    "seeds_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed_df contains all the senses of the word machine_nn01\n",
    "# we distinguish between provenance and provenance_type\n",
    "# provenance will refer to specific word, sense of semantic class ids\n",
    "# provenance_type will distinguish between different types of extension\n",
    "# define provenance, these words are \"seed\"\n",
    "seeds_df['provenance'] = [[[i,'seed',lemma_id]] for i in seeds_df.id] # for the seed sense we use the id of the word machine_nn0\n",
    "                                       # we use list here, reason is explained later, see provenance of synonyms\n",
    "seeds_df['provenance_type'] = 'seed' # categorize these lemmas as seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all synonyms for the seed senses\n",
    "# reminder synonyms uses same function as the /senses/ endpoint, flags should work here\n",
    "print(f\"Get all synonyms of the senses listed in {lemma_id}\")\n",
    "synonyms = [(s,query_oed(auth,'sense',s,\n",
    "                level='synonyms',\n",
    "                flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                        for s in tqdm(query_sense_ids)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform list of synonyms to a dataframe\n",
    "synonyms_df = pd.DataFrame([s for s_id,syn in synonyms for s in syn['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for synonyms the provenance_type is set to \"synonym\"\n",
    "synonyms_df['provenance_type'] = 'synonym'\n",
    "# for synonyms we refer the sense_id via which this synonym was retrieved\n",
    "synonyms_df['provenance'] = [[[s['id'],'synonym',s_id]] for s_id,syn in synonyms for s in syn['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove senses from synonyms that already appear in the seed_df\n",
    "# otherwise we'd have different types of provenance\n",
    "# for the same sense id\n",
    "# print(synonyms_df.shape)\n",
    "# synonyms_df = synonyms_df.loc[~synonyms_df.id.isin(seeds_df.id)]\n",
    "# print(synonyms_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explaining the line  [s_id for s_id,syn in synonyms for s in syn['data']]\n",
    "# remove later\n",
    "# print(synonyms[0][0]) # print the sense_id\n",
    "# print(synonyms[0][1]) # print synonyms for sense_id\n",
    "# print(synonyms[0][1]['data']) # get 'data' for synonyms with send_id\n",
    "# print(len(synonyms[0][1]['data'])) # number of senses\n",
    "# synonym_sense_ids = [s_id for s_id,syn in synonyms for s in syn['data']]\n",
    "# synonym_sense_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should 485 synonyms\n",
    "synonyms_df.provenance[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: we have some duplicates, i.e. some senses appear multiple times as synonym \n",
    "# for the collection of seed_sense\n",
    "# is this a problem?\n",
    "# in the code below we keep duplicates, but allow provenance to list all senses\n",
    "len(set(synonyms_df.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter(synonyms_df.id).most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonyms_df[synonyms_df.id==\"machina_nn01-38472486\"].provenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot = synonyms_df.groupby([\"id\"],as_index=True)['provenance_pivot'].apply(list).to_frame(name='provenance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonyms_df = synonyms_df.merge(pivot,right_index=True,left_on='id',how='left')\n",
    "#synonyms_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#synonyms_df.drop('provenance_pivot',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed + synonyms constitute the nucleas of our query\n",
    "# these are saved in the core_df\n",
    "# shape should be 485 (synonyms senses) + 26 (seed senses)\n",
    "core_df = pd.concat([seeds_df,synonyms_df])\n",
    "core_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# branch out from there\n",
    "# we save the lowest level of the semantic_class_last_id columns\n",
    "core_df['semantic_class_last_id'] = core_df['semantic_class_ids'].apply(get_last_id)\n",
    "core_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve all the _lowest_ (or last) semantic class ids for the core senses so far\n",
    "semantic_class_ids = set([s for l in core_df.semantic_class_last_id.to_list() for s in l])\n",
    "len(semantic_class_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we use the descendants endpoint\n",
    "# for each lowest semantic class id\n",
    "# we get all \"descendants\" which according the API documentation\n",
    "# returns an array of senses that belong to the semantic class\n",
    "# specified by ID, plus senses that belong to its child and descendant classes.\n",
    "print(\"Get all branches for seed senses and synonyms\")\n",
    "branches = [(idx,query_oed(auth,'semanticclass', idx, \n",
    "                        level='branchsenses', # \n",
    "                        flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                            for idx in tqdm(semantic_class_ids)]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert API response to dataframe\n",
    "branches_df = pd.DataFrame([s for idx,branch in branches for s in branch['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE: again we have duplicate \n",
    "# senses here, as some appear multiple time as\n",
    "# in the same semantic class (or as descendant)\n",
    "print(branches_df.shape[0],len(set(branches_df.id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provenance_type is branch with semantic class id \n",
    "# that was use for retrieving the sense is the provenance\n",
    "branches_df['provenance_type'] = 'branch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a provenance_pivot columsn, which shows\n",
    "# the semantic class id via which the sense was retrieved\n",
    "branches_df['provenance_pivot'] = [idx for idx, branch in branches for s in branch['data']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pivot = branches_df.groupby([\"id\"],as_index=True)['provenance_pivot'].apply(list).to_frame(name='provenance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branches_df = branches_df.merge(pivot,right_index=True,left_on='id',how='left')\n",
    "#branches_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branches_df.drop('provenance_pivot',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branches_df['semantic_class_last_id'] = branches_df['semantic_class_ids'].apply(get_last_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#branches_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_provenance_by_semantic_class(row):\n",
    "    \"\"\"\n",
    "    decide on the relation between the sense and the target querry\n",
    "    here we use the lowest semantic class id to decide on the relation\n",
    "    \n",
    "    if last semantic class id (sc_ids[-1]) == provenance id: then sense is sibling of provenance id\n",
    "    elif provenance semantic class id in the list of semantic class last ids\n",
    "    (but provenance not the last one): then sense is descendant of provenance id\n",
    "    Argument:\n",
    "        row (pd.Series): row of dataframe obtained from branchsenses endpoint\n",
    "    \n",
    "    Returns:\n",
    "        nested listed in the format of [lowest semantic class id, relation, provenance semantic class id]\n",
    "            in other words it said that for a given sense (which can have multiple semantic class ids)\n",
    "            the lowest semantic class id stands in the relation \"sibling\" or \"descendant\" of the \n",
    "            provenance semantic class id\n",
    "    \"\"\"\n",
    "\n",
    "    provenance = []\n",
    "    \n",
    "    for sc_ids in row.semantic_class_ids:\n",
    "        relation = ''\n",
    "        \n",
    "        \n",
    "        if sc_ids[-1] == row.provenance_pivot:\n",
    "            relation = 'sibling'\n",
    "            \n",
    "        elif (row.provenance_pivot in sc_ids):\n",
    "            relation = 'descendant'\n",
    "        \n",
    "        if relation:\n",
    "            provenance.append([sc_ids[-1], relation, row.provenance_pivot])\n",
    "    \n",
    "    if not provenance:\n",
    "        print(f'No descendants or siblings found for {row.id}')\n",
    " \n",
    "    return provenance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_df['provenance'] = branches_df.apply(get_provenance_by_semantic_class,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(100,200):\n",
    "#     print()\n",
    "#     print(branches_df.iloc[idx]['semantic_class_ids'])\n",
    "#     print(branches_df.iloc[idx]['semantic_class_last_id'])\n",
    "#     print(branches_df.iloc[idx]['provenance_pivot'])\n",
    "#     print(branches_df.iloc[idx]['provenance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df.to_pickle(f\"./data/extended_{lemma_id}.pickle\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "branches_df.drop('provenance_pivot',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate core and branch senses\n",
    "# ISSUE: have a closer look at the warning message\n",
    "extended_df = pd.concat([core_df,branches_df],sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df.shape[0] == core_df.shape[0] + branches_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_df = extend_from_lemma_query(credentials,lemma_id,start,end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_from_lemma_query_depr(auth,lemma_id,start=1750,end=1950):\n",
    "    \"\"\"Extends senses from a dataframe generate from accessing\n",
    "    the API via the word endpoint. The script first retrieves all\n",
    "    senses, then synonyms for these senses, then other senses that \n",
    "    match the semantic classes of the retrieved senses.\n",
    "    \n",
    "    This script also aims to record the \"provenance\" of words, \n",
    "    their relation to the initial query, which can help to \n",
    "    select of filter words later on.\n",
    "    \n",
    "    Arguments:\n",
    "        lemma_id (str)\n",
    "        start (int)\n",
    "        end (int)\n",
    "    Returns\n",
    "        a pandas.DataFrame\n",
    "    \"\"\"\n",
    "    # load seed query dataframe\n",
    "    query_df = pd.read_pickle(f\"./data/senses_{lemma_id}.pickle\")\n",
    "    \n",
    "    # use the sense endpoint to ensure all information \n",
    "    # can be properly concatenated in one dataframe\n",
    "    \n",
    "    # retrieve all sense ids\n",
    "    query_sense_ids = query_df.id.unique()\n",
    "    \n",
    "    # get all senses by sense id\n",
    "    print(f\"Get all sense for the lemma {lemma_id}\")\n",
    "    seeds = [(s,query_oed(auth,'sense',s,\n",
    "                    flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                        for s in tqdm(query_sense_ids)]\n",
    "    \n",
    "    # convert to dataframe\n",
    "    seeds_df = pd.DataFrame([seed['data'] for s_id,seed in seeds])\n",
    "    \n",
    "    # define provenance, these words are \"seed\"\n",
    "    seeds_df['provenance'] = seeds_df.id\n",
    "    seeds_df['provenance_type'] = 'seed'\n",
    "    \n",
    "    # get all synonyms for the seed senses\n",
    "    print(f\"Get all synonyms of the senses listed in {lemma_id}\")\n",
    "    synonyms = [(s,query_oed(auth,'sense',s,\n",
    "                    level='synonyms',\n",
    "                    flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                            for s in tqdm(query_sense_ids)]\n",
    "\n",
    "    # transform list of synonyms to a dataframe\n",
    "    synonyms_df = pd.DataFrame([s for s_id,syn in synonyms for s in syn['data']])\n",
    "    \n",
    "    # these items have provenancy type \"synonym\"\n",
    "    synonyms_df['provenance'] = [s_id for s_id,syn in synonyms for s in syn['data']]\n",
    "    synonyms_df['provenance_type'] = 'synonym'\n",
    "    \n",
    "    # seed + synonyms constitute the nucleas of our query\n",
    "    # branch from there\n",
    "    core_df = pd.concat([seeds_df,synonyms_df])\n",
    "    core_df['semantic_class_last_id'] = core_df['semantic_class_ids'].apply(get_last_id)\n",
    "    \n",
    "    # retrieve all semantic class ids for the senses so far\n",
    "    semantic_class_ids = set([s for l in core_df.semantic_class_last_id.to_list() for s in l])\n",
    "\n",
    "    # get all the branches for the retrieve semantic class ids\n",
    "    print(\"Get all branches for seed senses and synonyms\")\n",
    "    branches = [(idx,query_oed(auth,'semanticclass', idx, \n",
    "                        level='branchsenses',\n",
    "                        flags=f\"current_in='{start}-{end}'&limit=1000\"))\n",
    "                            for idx in tqdm(semantic_class_ids)]\n",
    "    \n",
    "    # convert API response to dataframe\n",
    "    branches_df = pd.DataFrame([s for idx,branch in branches for s in branch['data']])\n",
    "    \n",
    "    # provenance_type is branch with semantic class id \n",
    "    # that was use for retrieving the sense is the provenance\n",
    "    branches_df['provenance'] = [idx for idx,branch in branches for s in branch['data']]\n",
    "    branches_df['provenance_type'] = 'branch'\n",
    "    \n",
    "    branches_df['semantic_class_last_id'] = branches_df.semantic_class_ids.apply(get_last_id)\n",
    "    \n",
    "    # remove senses that already appear in the core_df\n",
    "    branches_df_red = branches_df.loc[~branches_df.id.isin(core_df.id)]\n",
    "    \n",
    "    # concatenate core and branch senses\n",
    "    extended_df = pd.concat([core_df,branches_df_red])\n",
    "    \n",
    "    # refine the provenance type\n",
    "    # if the last semantic class id is not equal to provenance\n",
    "    # this row is a child or descendant\n",
    "    check_membership = lambda row : row.provenance in row.semantic_class_last_id\n",
    "    extended_df.loc[(~extended_df.apply(check_membership,axis=1)) & (extended_df.provenance_type=='branch'),\n",
    "                [\"provenance_type\"]]  = \"branch_descendant\"\n",
    "    \n",
    "    # save information\n",
    "    extended_df.to_pickle(f'{dp}/senses_{lemma_id}_extended.pickle')\n",
    "    return extended_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
