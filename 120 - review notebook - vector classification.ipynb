{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tasks import wsd\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.dataset_download import harvest_data_from_extended_senses\n",
    "from utils.classificaton_utils import binarize, vectorize_target_expressions,cosine_similiarity\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "lemma,pos = 'machine', \"NN\"\n",
    "senses = {'machine_nn01-38474140'} # machine_nn01-38475772 machine_nn01-38475923 machine_nn01-38475835 machine_nn01-38474140\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 433\n",
      "\n",
      "\n",
      "# of seed senses 26 \n",
      "# of synonyms 383 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 44 \n",
      "# of branches selected 0\n",
      "[LOG] 2905 quotations selected\n",
      "[LOG] train = 2136 val = 292 test = 477 quotations\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = binarize(lemma,\n",
    "                        pos,\n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=2000,\n",
    "                        filter_val_by_year=True,\n",
    "                        filter_test_by_year=True,\n",
    "                        eval_mode=eval_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_col = \"vector_bert_base_-1,-2,-3,-4_mean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.concat([df_train,df_val], axis=0)\n",
    "X,y = list(df[vector_col].values), list(df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96       443\n           1       0.45      0.41      0.43        34\n\n    accuracy                           0.92       477\n   macro avg       0.70      0.69      0.69       477\nweighted avg       0.92      0.92      0.92       477\n\n"
     ]
    }
   ],
   "source": [
    "svm_model = LinearSVC(random_state=0, C=.1, tol=1e-5,class_weight='balanced')\n",
    "svm_model.fit(X,y)\n",
    "y_pred = wsd.clf_svm(vector_col,df_test, svm_model)\n",
    "print(classification_report(y_pred,list(df_test.label.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.96      0.97      0.96       438\n           1       0.61      0.49      0.54        39\n\n    accuracy                           0.93       477\n   macro avg       0.78      0.73      0.75       477\nweighted avg       0.93      0.93      0.93       477\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perc_model = Perceptron(validation_fraction=.2, early_stopping=True,class_weight='balanced')\n",
    "perc_model.fit(X,y)\n",
    "y_pred = wsd.clf_perceptron(vector_col,df_test, perc_model)\n",
    "print(classification_report(y_pred,list(df_test.label.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.97      0.96      0.97       450\n           1       0.45      0.52      0.48        27\n\n    accuracy                           0.94       477\n   macro avg       0.71      0.74      0.72       477\nweighted avg       0.94      0.94      0.94       477\n\n"
     ]
    }
   ],
   "source": [
    "mlperc_model = MLPClassifier(validation_fraction=.2, early_stopping=True, solver='lbfgs',activation='relu')\n",
    "mlperc_model.fit(X,y)\n",
    "y_pred = wsd.clf_perceptron(vector_col,df_test, mlperc_model)\n",
    "print(classification_report(y_pred,list(df_test.label.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}