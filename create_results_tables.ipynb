{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils.classificaton_utils import evaluate_results"
   ]
  },
  {
   "source": [
    "# Table and 1.2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '' # '' or '_lemma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_1850 = evaluate_results(Path(f'results_1850{extension}'))\n",
    "results_1900 = evaluate_results(Path(f'results_1900{extension}'))\n",
    "#results_2000 = evaluate_results(Path('results_2000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1850 = pd.DataFrame.from_dict(results_1850, orient='index', columns=['precision','recall','fscore'])\n",
    "df_1900 = pd.DataFrame.from_dict(results_1900, orient='index', columns=['precision','recall','fscore'])\n",
    "#df_2000 = pd.DataFrame.from_dict(results_2000, orient='index', columns=['precision','recall','fscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lrr}\n\\toprule\n{} &  fscore &  fscore \\\\\n\\midrule\nrandom                                             &   0.409 &   0.400 \\\\\ndef\\_tok\\_overlap\\_ranking                            &   0.577 &   0.586 \\\\\nsent\\_embedding                                     &   0.573 &   0.577 \\\\\nw2v\\_lesk\\_ranking                                   &   0.613 &   0.609 \\\\\nsvm\\_wemb\\_baseline                                  &   0.528 &   0.543 \\\\\nrandom                                             &   0.409 &   0.400 \\\\\ndef\\_tok\\_overlap\\_ranking                            &   0.577 &   0.586 \\\\\nsent\\_embedding                                     &   0.573 &   0.577 \\\\\nw2v\\_lesk\\_ranking                                   &   0.613 &   0.609 \\\\\nsvm\\_wemb\\_baseline                                  &   0.528 &   0.543 \\\\\nbert\\_binary\\_centroid\\_vector\\_bert\\_base\\_-1,-2,-3,... &   0.613 &   0.607 \\\\\nbert\\_centroid\\_sense\\_vector\\_bert\\_base\\_-1,-2,-3,-... &   0.764 &   0.755 \\\\\nbert\\_contrast\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean    &   0.526 &   0.521 \\\\\nbert\\_svm\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean         &   0.702 &   0.693 \\\\\nbert\\_perceptron\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean  &   0.669 &   0.669 \\\\\nbert\\_ml\\_perceptron\\_vector\\_bert\\_base\\_-1,-2,-3,-4... &   0.713 &   0.721 \\\\\nbert\\_binary\\_centroid\\_vector\\_blert\\_base\\_-1,-2,-3... &   0.599 &   0.596 \\\\\nbert\\_centroid\\_sense\\_vector\\_blert\\_base\\_-1,-2,-3,... &   0.780 &   0.775 \\\\\nbert\\_contrast\\_vector\\_blert\\_base\\_-1,-2,-3,-4\\_mean   &   0.545 &   0.534 \\\\\nbert\\_svm\\_vector\\_blert\\_base\\_-1,-2,-3,-4\\_mean        &   0.705 &   0.718 \\\\\nbert\\_perceptron\\_vector\\_blert\\_base\\_-1,-2,-3,-4\\_mean &   0.675 &   0.678 \\\\\nbert\\_ml\\_perceptron\\_vector\\_blert\\_base\\_-1,-2,-3,-... &   0.721 &   0.731 \\\\\nbert\\_binary\\_centroid\\_vector\\_bert\\_1850\\_-1,-2,-3,... &   0.594 &   0.599 \\\\\nbert\\_centroid\\_sense\\_vector\\_bert\\_1850\\_-1,-2,-3,-... &   0.775 &   0.763 \\\\\nbert\\_contrast\\_vector\\_bert\\_1850\\_-1,-2,-3,-4\\_mean    &   0.553 &   0.545 \\\\\nbert\\_svm\\_vector\\_bert\\_1850\\_-1,-2,-3,-4\\_mean         &   0.708 &   0.710 \\\\\nbert\\_perceptron\\_vector\\_bert\\_1850\\_-1,-2,-3,-4\\_mean  &   0.682 &   0.670 \\\\\nbert\\_ml\\_perceptron\\_vector\\_bert\\_1850\\_-1,-2,-3,-4... &   0.711 &   0.723 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "df_fscores = pd.concat([df_1850['fscore'],df_1900['fscore']],axis=1) # ,df_2000['fscore']\n",
    "cols_baselines = [\"random\", \"def_tok_overlap_ranking\", \"sent_embedding\", \"w2v_lesk_ranking\", \"svm_wemb_baseline\"]\n",
    "cols_bert = [c for c in df_fscores.index if not 'ts' in c or 'contrast' in c]\n",
    "df_fscores = df_fscores.loc[cols_baselines + cols_bert]\n",
    "print(df_fscores.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_baselines + cols_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_1850 = [r for r in df_fscores.index if '1850' in r]\n",
    "rows_1900 = [r for r in df_fscores.index if 'blert' in r]\n",
    "rows_2000 = [r for r in df_fscores.index if 'bert_base' in r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_1850_2000 = df_1850.loc[df_1850.index.isin(rows_1850)].fscore.values - df_1850.loc[df_1850.index.isin(rows_2000)].fscore.values\n",
    "diff_1900_2000 = df_1900.loc[df_1900.index.isin(rows_1900)].fscore.values - df_1900.loc[df_1900.index.isin(rows_2000)].fscore.values\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Table 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lrr}\n\\toprule\n{} &      0 &      1 \\\\\n\\midrule\nbert\\_binary\\_centroid\\_vector\\_bert\\_base\\_-1,-2,-3,... & -0.024 & -0.008 \\\\\nbert\\_centroid\\_sense\\_vector\\_bert\\_base\\_-1,-2,-3,-... &  0.021 &  0.037 \\\\\nbert\\_contrast\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean    &  0.009 &  0.009 \\\\\nbert\\_svm\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean         &  0.011 &  0.048 \\\\\nbert\\_perceptron\\_vector\\_bert\\_base\\_-1,-2,-3,-4\\_mean  &  0.017 &  0.012 \\\\\nbert\\_ml\\_perceptron\\_vector\\_bert\\_base\\_-1,-2,-3,-4... & -0.005 &  0.020 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "df_diff = pd.DataFrame([diff_1850_2000,diff_1900_2000],columns=rows_2000).T\n",
    "#df_diff['sum'] = df_diff.sum(axis=1)\n",
    "print(df_diff.to_latex())"
   ]
  },
  {
   "source": [
    "# Table 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ts = evaluate_results(Path()) # 'results_2000_wo_time_filter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.DataFrame.from_dict(results_ts, orient='index', columns=['precision','recall','fscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bert_centroid_sense_vector_bert_base_-1,-2,-3,-4_mean                 0.753\n",
       "bert_ts_nearest_centroid_sense_vector_bert_base_-1,-2,-3,-4_mean      0.687\n",
       "bert_ts_weighted_centroid_sense_vector_bert_base_-1,-2,-3,-4_mean     0.752\n",
       "bert_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean                0.757\n",
       "bert_ts_nearest_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean     0.696\n",
       "bert_ts_weighted_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean    0.756\n",
       "bert_centroid_sense_vector_bert_1850_-1,-2,-3,-4_mean                 0.752\n",
       "bert_ts_nearest_centroid_sense_vector_bert_1850_-1,-2,-3,-4_mean      0.693\n",
       "bert_ts_weighted_centroid_sense_vector_bert_1850_-1,-2,-3,-4_mean     0.753\n",
       "Name: fscore, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_ts['fscore']"
   ]
  },
  {
   "source": [
    "# Curated examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_curated_seed = evaluate_results(Path(f'results_curated_1920_seed'))\n",
    "results_curated_synonym = evaluate_results(Path(f'results_curated_1920_syn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_seed = pd.DataFrame.from_dict(results_curated_seed, orient='index', columns=['precision','recall','fscore'])\n",
    "df_curated_synonym = pd.DataFrame.from_dict(results_curated_synonym, orient='index', columns=['precision','recall','fscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lrr}\n\\toprule\n{} &  vertical &  horizontal \\\\\n\\midrule\nbert\\_centroid\\_sense\\_vector\\_bert\\_base\\_-1,-2,-3,-... &     0.813 &       0.740 \\\\\nbert\\_ts\\_weighted\\_centroid\\_sense\\_vector\\_bert\\_bas... &     0.748 &       0.731 \\\\\nbert\\_ml\\_perceptron\\_vector\\_bert\\_base\\_-1,-2,-3,-4... &     0.818 &       0.725 \\\\\nbert\\_centroid\\_sense\\_vector\\_blert\\_base\\_-1,-2,-3,... &     0.819 &       0.750 \\\\\nbert\\_ts\\_weighted\\_centroid\\_sense\\_vector\\_blert\\_ba... &     0.769 &       0.756 \\\\\nbert\\_ml\\_perceptron\\_vector\\_blert\\_base\\_-1,-2,-3,-... &     0.757 &       0.733 \\\\\nbert\\_centroid\\_sense\\_vector\\_bert\\_1850\\_-1,-2,-3,-... &     0.794 &       0.755 \\\\\nbert\\_ts\\_weighted\\_centroid\\_sense\\_vector\\_bert\\_185... &     0.738 &       0.742 \\\\\nbert\\_ml\\_perceptron\\_vector\\_bert\\_1850\\_-1,-2,-3,-4... &     0.753 &       0.713 \\\\\n\\bottomrule\n\\end{tabular}\n\n"
     ]
    }
   ],
   "source": [
    "df_fscore = pd.concat([df_curated_seed['fscore'],df_curated_synonym['fscore']], axis=1)\n",
    "df_fscore.columns=['vertical','horizontal']\n",
    "print(df_fscore.to_latex())"
   ]
  },
  {
   "source": [
    "# Assess Statistical Significance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_results(Path(\"results_1850/\"))\n",
    "\n",
    "selected = \"bert_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean\"\n",
    "\n",
    "selected_pred = res[method][\"pred\"]\n",
    "print (method, res[method][\"metrics\"], \"\\n\\nIs the difference significant?\\n\")\n",
    "\n",
    "for method,values in res.items():\n",
    "    if method != selected:\n",
    "        pred = values[\"pred\"]\n",
    "        p_value = scipy.stats.ttest_rel(selected_pred,pred)[1]\n",
    "        if p_value<0.05:\n",
    "            print (method, values[\"metrics\"], \"YES\")\n",
    "        else:\n",
    "            print (method, values[\"metrics\"], \"NO p_value:\",round(p_value,5))"
   ]
  }
 ]
}