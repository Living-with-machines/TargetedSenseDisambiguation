{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from utils.classificaton_utils import evaluate_results"
   ]
  },
  {
   "source": [
    "# Table and 1.2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension = '' # '' or '_lemma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_1850 = evaluate_results(Path(f'results_1850{extension}'))\n",
    "#results_1900 = evaluate_results(Path(f'results_1900{extension}'))\n",
    "#results_2000 = evaluate_results(Path('results_2000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1850 = pd.DataFrame.from_dict(results_1850, orient='index', columns=['precision','recall','fscore','preds'])\n",
    "df_1900 = pd.DataFrame.from_dict(results_1900, orient='index', columns=['precision','recall','fscore','preds'])\n",
    "#df_2000 = pd.DataFrame.from_dict(results_2000, orient='index', columns=['precision','recall','fscore','preds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fscores = pd.concat([df_1850['fscore'],df_1900['fscore']],axis=1) # ,df_2000['fscore']\n",
    "cols_baselines = [\"random\", \"def_tok_overlap_ranking\", \"sent_embedding\", \"w2v_lesk_ranking\", \"svm_wemb_baseline\"]\n",
    "cols_bert = [c for c in df_fscores.index if not 'ts' in c or 'contrast' in c]\n",
    "df_fscores = df_fscores.loc[cols_baselines + cols_bert]\n",
    "print(df_fscores.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_baselines + cols_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_1850 = [r for r in df_fscores.index if '1850' in r]\n",
    "rows_1900 = [r for r in df_fscores.index if 'blert' in r]\n",
    "rows_2000 = [r for r in df_fscores.index if 'bert_base' in r]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_1850_2000 = df_1850.loc[df_1850.index.isin(rows_1850)].fscore.values - df_1850.loc[df_1850.index.isin(rows_2000)].fscore.values\n",
    "diff_1900_2000 = df_1900.loc[df_1900.index.isin(rows_1900)].fscore.values - df_1900.loc[df_1900.index.isin(rows_2000)].fscore.values\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Table 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff = pd.DataFrame([diff_1850_2000,diff_1900_2000],columns=rows_2000).T\n",
    "#df_diff['sum'] = df_diff.sum(axis=1)\n",
    "print(df_diff.to_latex())"
   ]
  },
  {
   "source": [
    "# Table 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ts = evaluate_results(Path()) # 'results_2000_wo_time_filter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.DataFrame.from_dict(results_ts, orient='index', columns=['precision','recall','fscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts['fscore']"
   ]
  },
  {
   "source": [
    "# Curated examples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_curated_seed = evaluate_results(Path(f'results_curated_1920_seed'))\n",
    "results_curated_synonym = evaluate_results(Path(f'results_curated_1920_syn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_curated_seed = pd.DataFrame.from_dict(results_curated_seed, orient='index', columns=['precision','recall','fscore'])\n",
    "df_curated_synonym = pd.DataFrame.from_dict(results_curated_synonym, orient='index', columns=['precision','recall','fscore'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fscore = pd.concat([df_curated_seed['fscore'],df_curated_synonym['fscore']], axis=1)\n",
    "df_fscore.columns=['vertical','horizontal']\n",
    "print(df_fscore.to_latex())"
   ]
  },
  {
   "source": [
    "# Assess Statistical Significance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = evaluate_results(Path(\"results_1850/\"))\n",
    "\n",
    "selected = \"bert_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean\"\n",
    "\n",
    "selected_pred = res[selected][3][0]\n",
    "print (selected, res[selected][:3], \"\\n\\nIs the difference significant?\\n\")\n",
    "\n",
    "for method,values in res.items():\n",
    "    if method != selected:\n",
    "        pred = values[3][0]\n",
    "        p_value = scipy.stats.ttest_rel(selected_pred,pred)[1]\n",
    "        if p_value<0.05:\n",
    "            print (method, values[:3], \"YES\")\n",
    "        else:\n",
    "            print (method, values[:3], \"NO p_value:\",round(p_value,5))"
   ]
  }
 ]
}