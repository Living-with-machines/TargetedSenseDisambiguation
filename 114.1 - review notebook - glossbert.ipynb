{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from pathlib import Path\n",
    "from tasks import wsd\n",
    "from utils import nlp_tools\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from utils.dataset_download import harvest_data_from_extended_senses\n",
    "from utils.classificaton_utils import binarize, vectorize_target_expressions,cosine_similiarity,eval_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = 'machine'\n",
    "pos = 'NN'\n",
    "senses = {'machine_nn01-38474140'} # machine_nn01-38475772 machine_nn01-38475923 machine_nn01-38475835 machine_nn01-38474140\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 433\n",
      "\n",
      "\n",
      "# of seed senses 26 \n",
      "# of synonyms 383 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 44 \n",
      "# of branches selected 0\n",
      "[LOG] #rows before removing None vector (1947, 21)\n",
      "[LOG] #rows after removing None vector (1911, 21)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = binarize(lemma,\n",
    "                        pos,\n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=2000,\n",
    "                        eval_mode=eval_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             sense_id                                   lemma_definition  \\\n",
       "0  body_nn01-17170653  The complete physical form of a person or anim...   \n",
       "1  man_nn01-110482153  An adult male human being. Without explicit co...   \n",
       "2  body_nn01-17169813  The complete physical form of a person or anim...   \n",
       "\n",
       "                                          definition    word_id lemma  \\\n",
       "0  Particular technical uses. The part of a vehic...  body_nn01  body   \n",
       "1  As vocative or as int., introducing a remark o...   man_nn01   man   \n",
       "2  Contrasted with the soul. Cf. soul body n. at ...  body_nn01  body   \n",
       "\n",
       "          quotation_id                                             source  \\\n",
       "0  body_nn01-132916428  {'title': 'Material Handling Engin.', 'author'...   \n",
       "1   man_nn01-110482440  {'title': 'Shaela', 'author': 'R. Bulter', 'ge...   \n",
       "2   body_nn01-17169857  {'title': 'Ess. Man', 'author': 'A. Pope', 'ge...   \n",
       "\n",
       "                                                text    year  \\\n",
       "0  {'keyword': 'bodies', 'full_text': 'After car ...  1990.0   \n",
       "1  {'keyword': 'Min', 'full_text': 'Min A'm vexed...  1976.0   \n",
       "2  {'keyword': 'Body', 'full_text': 'All are but ...  1733.0   \n",
       "\n",
       "                                           full_text  ... keyword_offset  \\\n",
       "0  After car bodies are painted, they are moved i...  ...           10.0   \n",
       "1                         Min A'm vexed ta hear yun.  ...            0.0   \n",
       "2  All are but parts of one stupendous Whole, Who...  ...           49.0   \n",
       "\n",
       "                   vector_bert_base_-1,-2,-3,-4_mean  \\\n",
       "0  [1.2747291, 0.25178745, 0.69486666, 0.42832682...   \n",
       "1  [-0.10557328, 0.24347349, 0.731555, -0.4305202...   \n",
       "2  [0.8197431, 0.04237363, 0.6312159, -0.2658673,...   \n",
       "\n",
       "                       vector_blert_-1,-2,-3,-4_mean label   id daterange  \\\n",
       "0  [1.5054287, 1.1386966, 1.3405375, 0.8012274, -...     0  NaN       NaN   \n",
       "1  [-0.49209523, 0.7658461, 0.07512934, 0.0148925...     0  NaN       NaN   \n",
       "2  [0.60478234, 0.58020014, 0.053836707, -0.06571...     0  NaN       NaN   \n",
       "\n",
       "  provenance provenance_type relation_to_core_senses relation_to_seed_senses  \n",
       "0        NaN             NaN                     NaN                     NaN  \n",
       "1        NaN             NaN                     NaN                     NaN  \n",
       "2        NaN             NaN                     NaN                     NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_id</th>\n      <th>lemma_definition</th>\n      <th>definition</th>\n      <th>word_id</th>\n      <th>lemma</th>\n      <th>quotation_id</th>\n      <th>source</th>\n      <th>text</th>\n      <th>year</th>\n      <th>full_text</th>\n      <th>...</th>\n      <th>keyword_offset</th>\n      <th>vector_bert_base_-1,-2,-3,-4_mean</th>\n      <th>vector_blert_-1,-2,-3,-4_mean</th>\n      <th>label</th>\n      <th>id</th>\n      <th>daterange</th>\n      <th>provenance</th>\n      <th>provenance_type</th>\n      <th>relation_to_core_senses</th>\n      <th>relation_to_seed_senses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>body_nn01-17170653</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Particular technical uses. The part of a vehic...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-132916428</td>\n      <td>{'title': 'Material Handling Engin.', 'author'...</td>\n      <td>{'keyword': 'bodies', 'full_text': 'After car ...</td>\n      <td>1990.0</td>\n      <td>After car bodies are painted, they are moved i...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>[1.2747291, 0.25178745, 0.69486666, 0.42832682...</td>\n      <td>[1.5054287, 1.1386966, 1.3405375, 0.8012274, -...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>man_nn01-110482153</td>\n      <td>An adult male human being. Without explicit co...</td>\n      <td>As vocative or as int., introducing a remark o...</td>\n      <td>man_nn01</td>\n      <td>man</td>\n      <td>man_nn01-110482440</td>\n      <td>{'title': 'Shaela', 'author': 'R. Bulter', 'ge...</td>\n      <td>{'keyword': 'Min', 'full_text': 'Min A'm vexed...</td>\n      <td>1976.0</td>\n      <td>Min A'm vexed ta hear yun.</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>[-0.10557328, 0.24347349, 0.731555, -0.4305202...</td>\n      <td>[-0.49209523, 0.7658461, 0.07512934, 0.0148925...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>body_nn01-17169813</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Contrasted with the soul. Cf. soul body n. at ...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-17169857</td>\n      <td>{'title': 'Ess. Man', 'author': 'A. Pope', 'ge...</td>\n      <td>{'keyword': 'Body', 'full_text': 'All are but ...</td>\n      <td>1733.0</td>\n      <td>All are but parts of one stupendous Whole, Who...</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>[0.8197431, 0.04237363, 0.6312159, -0.2658673,...</td>\n      <td>[0.60478234, 0.58020014, 0.053836707, -0.06571...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
       "       'quotation_id', 'source', 'text', 'year', 'full_text', 'keyword',\n",
       "       'keyword_offset', 'vector_bert_base_-1,-2,-3,-4_mean',\n",
       "       'vector_blert_-1,-2,-3,-4_mean', 'label', 'id', 'daterange',\n",
       "       'provenance', 'provenance_type', 'relation_to_core_senses',\n",
       "       'relation_to_seed_senses'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enclose_keyword(row,enclose_token='[TARGET]'):\n",
    "    \"\"\"enclose keyword with specific token to point\n",
    "    learner towards to word it has to focus on\n",
    "    \"\"\"\n",
    "    sentence = ''\n",
    "    for i,c in enumerate(row.full_text):\n",
    "        if i == int(row.keyword_offset):\n",
    "            sentence+=enclose_token + ' '\n",
    "        elif i ==int(row.keyword_offset + len(row.keyword)):\n",
    "            sentence+= ' ' + enclose_token\n",
    "        sentence+=c\n",
    "    return sentence\n",
    "\n",
    "def merge_quotation_gloss(row):\n",
    "    out_string = '[GLOSS] '\n",
    "    if row.definition:\n",
    "        out_string+=row.definition\n",
    "    out_string+=' [QUOT] '  \n",
    "    if row.enclosed_quotation:\n",
    "        out_string+=row.enclosed_quotation\n",
    "    return out_string\n",
    "\n",
    "def merge_quotation_keyword(row):\n",
    "    out_string = '[TARGET] '\n",
    "    if row.keyword:\n",
    "        out_string+=row.keyword\n",
    "    out_string+=' [QUOT] '  \n",
    "    if row.enclosed_quotation:\n",
    "        out_string+=row.enclosed_quotation\n",
    "    return out_string\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('./data/training_data')\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_out_path = path / f\"{lemma}_{'_'.join(senses)}\"\n",
    "csv_out_path.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['enclosed_quotation'] = df_train.apply(enclose_keyword, axis=1)\n",
    "df_train['train_text'] = df_train.apply(merge_quotation_keyword, axis=1)\n",
    "df_train[['train_text','label']].to_csv(csv_out_path / \"train.csv\",index = False, sep='\\t')    \n",
    "df_val['enclosed_quotation'] = df_val.apply(enclose_keyword, axis=1)\n",
    "df_val['train_text'] = df_val.apply(merge_quotation_keyword, axis=1)\n",
    "df_val[['train_text','label']].to_csv(csv_out_path / \"dev.csv\",index = False, sep='\\t')        \n",
    "df_test['enclosed_quotation'] = df_test.apply(enclose_keyword, axis=1)\n",
    "df_test['train_text'] = df_test.apply(merge_quotation_keyword, axis=1)\n",
    "df_test[['train_text','label']].to_csv(csv_out_path / \"test.csv\",index = False, sep='\\t')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-14 16:01:53,769 Reading data from data/training_data/machine_machine_nn01-38474140\n",
      "2021-01-14 16:01:53,770 Train: data/training_data/machine_machine_nn01-38474140/train.csv\n",
      "2021-01-14 16:01:53,770 Dev: data/training_data/machine_machine_nn01-38474140/dev.csv\n",
      "2021-01-14 16:01:53,770 Test: data/training_data/machine_machine_nn01-38474140/test.csv\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = csv_out_path\n",
    "\n",
    "# column format indicating which columns hold the text and label(s)\n",
    "column_name_map = {0: \"text\", 1: \"label\"}\n",
    "\n",
    "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                         delimiter='\\t',    # tab-separated files\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-14 16:01:56,791 Computing label dictionary. Progress:\n",
      "100%|██████████| 1604/1604 [00:00<00:00, 2103.07it/s]2021-01-14 16:01:57,857 [b'0', b'1']\n",
      "Dictionary with 2 tags: 0, 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 4. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)\n",
    "\n",
    "# 5. initialize the text classifier trainer with Adam optimizer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "# 6. start the training\n",
    "trainer.train('models/taggers/trec',\n",
    "              learning_rate=1e-5, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=5, # terminate after 5 epochs\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}