{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from pathlib import Path\n",
    "from tasks import wsd\n",
    "from utils import nlp_tools\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.metrics import classification_report\n",
    "from flair.embeddings import TransformerWordEmbeddings\n",
    "from utils.dataset_download import harvest_data_from_extended_senses\n",
    "from utils.classificaton_utils import binarize, vectorize_target_expressions,cosine_similiarity,eval_lemma\n",
    "from torch.optim.adam import Adam\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = 'machine'\n",
    "pos = 'NN'\n",
    "senses = {'machine_nn01-38474140'} # machine_nn01-38475772 machine_nn01-38475923 machine_nn01-38475835 machine_nn01-38474140\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 433\n",
      "\n",
      "\n",
      "# of seed senses 26 \n",
      "# of synonyms 383 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 44 \n",
      "# of branches selected 0\n",
      "[LOG] #rows before removing None vector (1947, 21)\n",
      "[LOG] #rows after removing None vector (1911, 21)\n"
     ]
    }
   ],
   "source": [
    "df_train, df_val, df_test = binarize(lemma,\n",
    "                        pos,\n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=2000,\n",
    "                        eval_mode=eval_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   sense_id  \\\n",
       "238   machine_nn01-38474140   \n",
       "305   machine_nn01-38474140   \n",
       "713   machine_nn01-38474140   \n",
       "938   machine_nn01-38474140   \n",
       "1042  machine_nn01-38474140   \n",
       "1056  machine_nn01-38474140   \n",
       "\n",
       "                                       lemma_definition  \\\n",
       "238   A complex device, consisting of a number of in...   \n",
       "305   A complex device, consisting of a number of in...   \n",
       "713   A complex device, consisting of a number of in...   \n",
       "938   A complex device, consisting of a number of in...   \n",
       "1042  A complex device, consisting of a number of in...   \n",
       "1056  A complex device, consisting of a number of in...   \n",
       "\n",
       "                                             definition       word_id  \\\n",
       "238   A living body, esp. the human body considered ...  machine_nn01   \n",
       "305   A living body, esp. the human body considered ...  machine_nn01   \n",
       "713   A living body, esp. the human body considered ...  machine_nn01   \n",
       "938   A living body, esp. the human body considered ...  machine_nn01   \n",
       "1042  A living body, esp. the human body considered ...  machine_nn01   \n",
       "1056  A living body, esp. the human body considered ...  machine_nn01   \n",
       "\n",
       "        lemma           quotation_id  \\\n",
       "238   machine  machine_nn01-38474169   \n",
       "305   machine  machine_nn01-38474177   \n",
       "713   machine  machine_nn01-38474195   \n",
       "938   machine  machine_nn01-38474223   \n",
       "1042  machine  machine_nn01-38474203   \n",
       "1056  machine  machine_nn01-38474212   \n",
       "\n",
       "                                                 source  \\\n",
       "238   {'title': 'Death's Vision', 'author': 'J. Reyn...   \n",
       "305   {'title': 'Spectator', 'author': 'J. Addison',...   \n",
       "713   {'title': 'Med. & Physical Jrnl.', 'author': N...   \n",
       "938   {'title': 'Of Human Bondage', 'author': 'W. S....   \n",
       "1042  {'title': 'Poems', 'author': 'W. Wordsworth', ...   \n",
       "1056  {'title': 'Telegraphy', 'author': 'W. H. Preec...   \n",
       "\n",
       "                                                   text    year  \\\n",
       "238   {'keyword': 'Machins', 'full_text': 'What Nobl...  1709.0   \n",
       "305   {'keyword': 'Machine', 'full_text': 'Cheerfuln...  1712.0   \n",
       "713   {'keyword': 'machine', 'full_text': 'When a pr...  1805.0   \n",
       "938   {'keyword': 'machine', 'full_text': 'He wonder...  1915.0   \n",
       "1042  {'keyword': 'machine', 'full_text': 'And now I...  1807.0   \n",
       "1056  {'keyword': 'machine', 'full_text': 'The human...  1876.0   \n",
       "\n",
       "                                              full_text  ... keyword_offset  \\\n",
       "238          What Nobler Souls the Nobler Machins Wear.  ...           29.0   \n",
       "305   Cheerfulness is..the best Promoter of Health. ...  ...           70.0   \n",
       "713   When a product of diseased action has been eff...  ...           82.0   \n",
       "938   He wondered whether at the very end, now that ...  ...           50.0   \n",
       "1042  And now I see with eye serene The very pulse o...  ...           52.0   \n",
       "1056  The human machine tires, and as a consequence ...  ...           10.0   \n",
       "\n",
       "                      vector_bert_base_-1,-2,-3,-4_mean  \\\n",
       "238   [0.5628562, -0.04788875, 0.074935675, -0.22630...   \n",
       "305   [0.0052292813, 0.12355395, 0.023108626, 0.2251...   \n",
       "713   [0.25928053, 0.049638785, 0.022315167, 0.34901...   \n",
       "938   [0.38040048, 0.38440758, 0.45397452, 0.1211486...   \n",
       "1042  [-0.46428305, 0.013232344, -0.595714, 0.049642...   \n",
       "1056  [0.6930934, 0.09074756, -0.13974331, 0.1105655...   \n",
       "\n",
       "                          vector_blert_-1,-2,-3,-4_mean label  \\\n",
       "238   [-0.15516208, 0.289941, -0.15124893, -0.206332...     1   \n",
       "305   [-0.04755735, 0.20182909, 0.33001357, -0.04851...     1   \n",
       "713   [-0.16033216, -0.16846322, 0.5062964, 0.102019...     1   \n",
       "938   [-0.059219074, 0.23112743, 0.42189148, 0.02944...     1   \n",
       "1042  [0.021248298, 0.28699854, 0.24638082, -0.01793...     1   \n",
       "1056  [0.11798739, -0.0029160888, 0.29418808, -0.076...     1   \n",
       "\n",
       "                         id  \\\n",
       "238   machine_nn01-38474140   \n",
       "305   machine_nn01-38474140   \n",
       "713   machine_nn01-38474140   \n",
       "938   machine_nn01-38474140   \n",
       "1042  machine_nn01-38474140   \n",
       "1056  machine_nn01-38474140   \n",
       "\n",
       "                                              daterange  \\\n",
       "238   {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "305   {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "713   {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "938   {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "1042  {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "1056  {'end': None, 'start': 1604, 'obsolete': False...   \n",
       "\n",
       "                                         provenance provenance_type  \\\n",
       "238   [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "305   [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "713   [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "938   [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "1042  [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "1056  [[machine_nn01-38474140, seed, machine_nn01]]            seed   \n",
       "\n",
       "      relation_to_core_senses  relation_to_seed_senses  \n",
       "238   {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "305   {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "713   {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "938   {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "1042  {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "1056  {machine_nn01-38474140}  {machine_nn01-38474140}  \n",
       "\n",
       "[6 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_id</th>\n      <th>lemma_definition</th>\n      <th>definition</th>\n      <th>word_id</th>\n      <th>lemma</th>\n      <th>quotation_id</th>\n      <th>source</th>\n      <th>text</th>\n      <th>year</th>\n      <th>full_text</th>\n      <th>...</th>\n      <th>keyword_offset</th>\n      <th>vector_bert_base_-1,-2,-3,-4_mean</th>\n      <th>vector_blert_-1,-2,-3,-4_mean</th>\n      <th>label</th>\n      <th>id</th>\n      <th>daterange</th>\n      <th>provenance</th>\n      <th>provenance_type</th>\n      <th>relation_to_core_senses</th>\n      <th>relation_to_seed_senses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>238</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474169</td>\n      <td>{'title': 'Death's Vision', 'author': 'J. Reyn...</td>\n      <td>{'keyword': 'Machins', 'full_text': 'What Nobl...</td>\n      <td>1709.0</td>\n      <td>What Nobler Souls the Nobler Machins Wear.</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>[0.5628562, -0.04788875, 0.074935675, -0.22630...</td>\n      <td>[-0.15516208, 0.289941, -0.15124893, -0.206332...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474177</td>\n      <td>{'title': 'Spectator', 'author': 'J. Addison',...</td>\n      <td>{'keyword': 'Machine', 'full_text': 'Cheerfuln...</td>\n      <td>1712.0</td>\n      <td>Cheerfulness is..the best Promoter of Health. ...</td>\n      <td>...</td>\n      <td>70.0</td>\n      <td>[0.0052292813, 0.12355395, 0.023108626, 0.2251...</td>\n      <td>[-0.04755735, 0.20182909, 0.33001357, -0.04851...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n    <tr>\n      <th>713</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474195</td>\n      <td>{'title': 'Med. &amp; Physical Jrnl.', 'author': N...</td>\n      <td>{'keyword': 'machine', 'full_text': 'When a pr...</td>\n      <td>1805.0</td>\n      <td>When a product of diseased action has been eff...</td>\n      <td>...</td>\n      <td>82.0</td>\n      <td>[0.25928053, 0.049638785, 0.022315167, 0.34901...</td>\n      <td>[-0.16033216, -0.16846322, 0.5062964, 0.102019...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n    <tr>\n      <th>938</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474223</td>\n      <td>{'title': 'Of Human Bondage', 'author': 'W. S....</td>\n      <td>{'keyword': 'machine', 'full_text': 'He wonder...</td>\n      <td>1915.0</td>\n      <td>He wondered whether at the very end, now that ...</td>\n      <td>...</td>\n      <td>50.0</td>\n      <td>[0.38040048, 0.38440758, 0.45397452, 0.1211486...</td>\n      <td>[-0.059219074, 0.23112743, 0.42189148, 0.02944...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n    <tr>\n      <th>1042</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474203</td>\n      <td>{'title': 'Poems', 'author': 'W. Wordsworth', ...</td>\n      <td>{'keyword': 'machine', 'full_text': 'And now I...</td>\n      <td>1807.0</td>\n      <td>And now I see with eye serene The very pulse o...</td>\n      <td>...</td>\n      <td>52.0</td>\n      <td>[-0.46428305, 0.013232344, -0.595714, 0.049642...</td>\n      <td>[0.021248298, 0.28699854, 0.24638082, -0.01793...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>machine_nn01-38474140</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A living body, esp. the human body considered ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474212</td>\n      <td>{'title': 'Telegraphy', 'author': 'W. H. Preec...</td>\n      <td>{'keyword': 'machine', 'full_text': 'The human...</td>\n      <td>1876.0</td>\n      <td>The human machine tires, and as a consequence ...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>[0.6930934, 0.09074756, -0.13974331, 0.1105655...</td>\n      <td>[0.11798739, -0.0029160888, 0.29418808, -0.076...</td>\n      <td>1</td>\n      <td>machine_nn01-38474140</td>\n      <td>{'end': None, 'start': 1604, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474140, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474140}</td>\n      <td>{machine_nn01-38474140}</td>\n    </tr>\n  </tbody>\n</table>\n<p>6 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "df_train[df_train.sense_id=='machine_nn01-38474140']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['body_nn01', 'man_nn01', 'machine_nn01', 'carcass_nn01',\n",
       "       'person_nn01', 'case_nn02', 'personage_nn01', 'corporeity_nn01',\n",
       "       'structure_nn01', 'dust_nn01', 'case_nn01', 'automaton_nn01',\n",
       "       'earth_nn01', 'soma_nn02', 'bulk_nn01', 'microcosm_nn01',\n",
       "       'personality_nn01', 'tabernacle_nn01', 'vessel_nn01',\n",
       "       'corpse_nn01', 'case_nn04', 'clay_nn01', 'clod_nn01',\n",
       "       'skinful_nn01', 'carrion_nn01', 'embodiment_nn01', 'corpus_nn01',\n",
       "       'flesh_nn01', 'soma_nn01', 'bloodbulk_nn01', 'earth_nn02',\n",
       "       'soulcase_nn02', 'corporation_nn01', 'chassis_nn01', 'bulk_nn03',\n",
       "       'bouk_nn01', 'outwall_nn01', 'case_nn03', 'incarnation_nn01',\n",
       "       'bonehouse_nn01', 'man_nn04', 'bulk_nn02', 'soulcase_nn01',\n",
       "       'godsimage_nn01', 'quarrons_nn01'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "df_train.word_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                   sense_id  \\\n",
       "0        body_nn01-17170653   \n",
       "1        man_nn01-110482153   \n",
       "2        body_nn01-17169813   \n",
       "3     machine_nn01-38474877   \n",
       "4     carcass_nn01-10177258   \n",
       "...                     ...   \n",
       "1215     man_nn01-110479060   \n",
       "1216   person_nn01-30950985   \n",
       "1217      clay_nn01-9320873   \n",
       "1218     case_nn02-10018131   \n",
       "1220     man_nn01-110487579   \n",
       "\n",
       "                                       lemma_definition  \\\n",
       "0     The complete physical form of a person or anim...   \n",
       "1     An adult male human being. Without explicit co...   \n",
       "2     The complete physical form of a person or anim...   \n",
       "3     A complex device, consisting of a number of in...   \n",
       "4     The dead body of a person or animal; but no lo...   \n",
       "...                                                 ...   \n",
       "1215  An adult male human being. Without explicit co...   \n",
       "1216  An individual human being; a man, woman, or ch...   \n",
       "1217  A stiff viscous earth found, in many varieties...   \n",
       "1218  A box, bag, or other receptacle, designed to c...   \n",
       "1220  An adult male human being. Without explicit co...   \n",
       "\n",
       "                                             definition       word_id  \\\n",
       "0     Particular technical uses. The part of a vehic...     body_nn01   \n",
       "1     As vocative or as int., introducing a remark o...      man_nn01   \n",
       "2     Contrasted with the soul. Cf. soul body n. at ...     body_nn01   \n",
       "3     A bicycle or tricycle; a motorcycle. Formerly ...  machine_nn01   \n",
       "4     The naked framework or ‘shell’ of a building b...  carcass_nn01   \n",
       "...                                                 ...           ...   \n",
       "1215  A husband. Now chiefly English regional (north...      man_nn01   \n",
       "1216  Law. An individual (natural person n.) or corp...   person_nn01   \n",
       "1217  Short for clay-pipe n. at  compounds 2 (colloq...     clay_nn01   \n",
       "1218  slang. A house, esp. one used as a brothel. Cf...     case_nn02   \n",
       "1220  In Cumbria: a cairn marking a summit or promin...      man_nn01   \n",
       "\n",
       "        lemma           quotation_id  \\\n",
       "0        body    body_nn01-132916428   \n",
       "1         man     man_nn01-110482440   \n",
       "2        body     body_nn01-17169857   \n",
       "3     machine  machine_nn01-38474966   \n",
       "4     carcass  carcass_nn01-10177295   \n",
       "...       ...                    ...   \n",
       "1215      man     man_nn01-110479206   \n",
       "1216   person   person_nn01-30951076   \n",
       "1217     clay      clay_nn01-9320896   \n",
       "1218     case     case_nn02-10018191   \n",
       "1220      man     man_nn01-110487624   \n",
       "\n",
       "                                                 source  \\\n",
       "0     {'title': 'Material Handling Engin.', 'author'...   \n",
       "1     {'title': 'Shaela', 'author': 'R. Bulter', 'ge...   \n",
       "2     {'title': 'Ess. Man', 'author': 'A. Pope', 'ge...   \n",
       "3     {'title': 'National Trust Mag.', 'author': Non...   \n",
       "4     {'title': 'New Pract. Builder', 'author': 'P. ...   \n",
       "...                                                 ...   \n",
       "1215  {'title': 'Four Years S. Afr.', 'author': 'C. ...   \n",
       "1216  {'title': 'Daily News', 'author': None, 'gende...   \n",
       "1217  {'title': 'Held in Bondage', 'author': '‘Ouida...   \n",
       "1218  {'title': 'Mop Fair', 'author': 'A. M. Binstea...   \n",
       "1220  {'title': 'Northern Affair', 'author': 'D. K. ...   \n",
       "\n",
       "                                                   text    year  \\\n",
       "0     {'keyword': 'bodies', 'full_text': 'After car ...  1990.0   \n",
       "1     {'keyword': 'Min', 'full_text': 'Min A'm vexed...  1976.0   \n",
       "2     {'keyword': 'Body', 'full_text': 'All are but ...  1733.0   \n",
       "3     {'keyword': 'machines', 'full_text': 'The cycl...  1992.0   \n",
       "4     {'keyword': 'Carcase', 'full_text': 'Carcase o...  1823.0   \n",
       "...                                                 ...     ...   \n",
       "1215  {'keyword': 'man', 'full_text': 'The wife brok...  1829.0   \n",
       "1216  {'keyword': 'persons', 'full_text': 'A Bill..e...  1900.0   \n",
       "1217  {'keyword': 'clays', 'full_text': 'Filthy bird...  1863.0   \n",
       "1218  {'keyword': 'case', 'full_text': 'They arrange...  1905.0   \n",
       "1220  {'keyword': 'man', 'full_text': 'Over the elep...  1964.0   \n",
       "\n",
       "                                              full_text  ... keyword_offset  \\\n",
       "0     After car bodies are painted, they are moved i...  ...           10.0   \n",
       "1                            Min A'm vexed ta hear yun.  ...            0.0   \n",
       "2     All are but parts of one stupendous Whole, Who...  ...           49.0   \n",
       "3     The cyclists..took on the circular 21- or 42-m...  ...           92.0   \n",
       "4     Carcase of a Building, the naked walls, and th...  ...            0.0   \n",
       "...                                                 ...  ...            ...   \n",
       "1215  The wife broke out, ‘You lament a brother, and...  ...           79.0   \n",
       "1216  A Bill..extending to juridical persons, that i...  ...           31.0   \n",
       "1217                Filthy bird's-eye, smoked in clays.  ...           29.0   \n",
       "1218  They arranges to stop ‘private’ in Brighton, a...  ...           57.0   \n",
       "1220  Over the elephant rocks and under the lee of t...  ...           55.0   \n",
       "\n",
       "                      vector_bert_base_-1,-2,-3,-4_mean  \\\n",
       "0     [1.2747291, 0.25178745, 0.69486666, 0.42832682...   \n",
       "1     [-0.10557328, 0.24347349, 0.731555, -0.4305202...   \n",
       "2     [0.8197431, 0.04237363, 0.6312159, -0.2658673,...   \n",
       "3     [-0.18150243, -0.24230756, -0.3336587, 0.34879...   \n",
       "4     [0.6567496, -0.050804906, 0.31024605, 0.059706...   \n",
       "...                                                 ...   \n",
       "1215  [-0.07307064, -0.31692728, 0.38834277, -0.2980...   \n",
       "1216  [0.030711764, 0.28706473, 0.6596842, -0.132111...   \n",
       "1217  [-0.016634814, 0.6912965, -0.18498293, -0.2104...   \n",
       "1218  [0.16278893, -0.17927478, 0.34916735, -0.34717...   \n",
       "1220  [0.12908892, 0.1654679, -0.077464886, -0.44454...   \n",
       "\n",
       "                          vector_blert_-1,-2,-3,-4_mean label  \\\n",
       "0     [1.5054287, 1.1386966, 1.3405375, 0.8012274, -...     0   \n",
       "1     [-0.49209523, 0.7658461, 0.07512934, 0.0148925...     0   \n",
       "2     [0.60478234, 0.58020014, 0.053836707, -0.06571...     0   \n",
       "3     [-0.14852196, 0.69629294, 0.30973893, 0.598406...     0   \n",
       "4     [0.41240987, 0.10217035, 0.48574266, 0.8627304...     0   \n",
       "...                                                 ...   ...   \n",
       "1215  [-0.20098017, 0.47577783, 0.013388823, -0.2808...     0   \n",
       "1216  [-0.42745396, 0.4621299, 0.34301567, 0.2193956...     0   \n",
       "1217  [-0.2833503, 0.80949837, -0.5981247, 0.4331013...     0   \n",
       "1218  [0.3253876, 0.12327082, -0.077930324, 0.450299...     0   \n",
       "1220  [-0.4877532, 0.62317544, -0.4543179, -0.167910...     0   \n",
       "\n",
       "                         id  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3     machine_nn01-38474877   \n",
       "4                       NaN   \n",
       "...                     ...   \n",
       "1215                    NaN   \n",
       "1216                    NaN   \n",
       "1217                    NaN   \n",
       "1218                    NaN   \n",
       "1220                    NaN   \n",
       "\n",
       "                                              daterange  \\\n",
       "0                                                   NaN   \n",
       "1                                                   NaN   \n",
       "2                                                   NaN   \n",
       "3     {'end': None, 'start': 1823, 'obsolete': False...   \n",
       "4                                                   NaN   \n",
       "...                                                 ...   \n",
       "1215                                                NaN   \n",
       "1216                                                NaN   \n",
       "1217                                                NaN   \n",
       "1218                                                NaN   \n",
       "1220                                                NaN   \n",
       "\n",
       "                                         provenance provenance_type  \\\n",
       "0                                               NaN             NaN   \n",
       "1                                               NaN             NaN   \n",
       "2                                               NaN             NaN   \n",
       "3     [[machine_nn01-38474877, seed, machine_nn01]]            seed   \n",
       "4                                               NaN             NaN   \n",
       "...                                             ...             ...   \n",
       "1215                                            NaN             NaN   \n",
       "1216                                            NaN             NaN   \n",
       "1217                                            NaN             NaN   \n",
       "1218                                            NaN             NaN   \n",
       "1220                                            NaN             NaN   \n",
       "\n",
       "      relation_to_core_senses  relation_to_seed_senses  \n",
       "0                         NaN                      NaN  \n",
       "1                         NaN                      NaN  \n",
       "2                         NaN                      NaN  \n",
       "3     {machine_nn01-38474877}  {machine_nn01-38474877}  \n",
       "4                         NaN                      NaN  \n",
       "...                       ...                      ...  \n",
       "1215                      NaN                      NaN  \n",
       "1216                      NaN                      NaN  \n",
       "1217                      NaN                      NaN  \n",
       "1218                      NaN                      NaN  \n",
       "1220                      NaN                      NaN  \n",
       "\n",
       "[1135 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_id</th>\n      <th>lemma_definition</th>\n      <th>definition</th>\n      <th>word_id</th>\n      <th>lemma</th>\n      <th>quotation_id</th>\n      <th>source</th>\n      <th>text</th>\n      <th>year</th>\n      <th>full_text</th>\n      <th>...</th>\n      <th>keyword_offset</th>\n      <th>vector_bert_base_-1,-2,-3,-4_mean</th>\n      <th>vector_blert_-1,-2,-3,-4_mean</th>\n      <th>label</th>\n      <th>id</th>\n      <th>daterange</th>\n      <th>provenance</th>\n      <th>provenance_type</th>\n      <th>relation_to_core_senses</th>\n      <th>relation_to_seed_senses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>body_nn01-17170653</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Particular technical uses. The part of a vehic...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-132916428</td>\n      <td>{'title': 'Material Handling Engin.', 'author'...</td>\n      <td>{'keyword': 'bodies', 'full_text': 'After car ...</td>\n      <td>1990.0</td>\n      <td>After car bodies are painted, they are moved i...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>[1.2747291, 0.25178745, 0.69486666, 0.42832682...</td>\n      <td>[1.5054287, 1.1386966, 1.3405375, 0.8012274, -...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>man_nn01-110482153</td>\n      <td>An adult male human being. Without explicit co...</td>\n      <td>As vocative or as int., introducing a remark o...</td>\n      <td>man_nn01</td>\n      <td>man</td>\n      <td>man_nn01-110482440</td>\n      <td>{'title': 'Shaela', 'author': 'R. Bulter', 'ge...</td>\n      <td>{'keyword': 'Min', 'full_text': 'Min A'm vexed...</td>\n      <td>1976.0</td>\n      <td>Min A'm vexed ta hear yun.</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>[-0.10557328, 0.24347349, 0.731555, -0.4305202...</td>\n      <td>[-0.49209523, 0.7658461, 0.07512934, 0.0148925...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>body_nn01-17169813</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Contrasted with the soul. Cf. soul body n. at ...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-17169857</td>\n      <td>{'title': 'Ess. Man', 'author': 'A. Pope', 'ge...</td>\n      <td>{'keyword': 'Body', 'full_text': 'All are but ...</td>\n      <td>1733.0</td>\n      <td>All are but parts of one stupendous Whole, Who...</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>[0.8197431, 0.04237363, 0.6312159, -0.2658673,...</td>\n      <td>[0.60478234, 0.58020014, 0.053836707, -0.06571...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>machine_nn01-38474877</td>\n      <td>A complex device, consisting of a number of in...</td>\n      <td>A bicycle or tricycle; a motorcycle. Formerly ...</td>\n      <td>machine_nn01</td>\n      <td>machine</td>\n      <td>machine_nn01-38474966</td>\n      <td>{'title': 'National Trust Mag.', 'author': Non...</td>\n      <td>{'keyword': 'machines', 'full_text': 'The cycl...</td>\n      <td>1992.0</td>\n      <td>The cyclists..took on the circular 21- or 42-m...</td>\n      <td>...</td>\n      <td>92.0</td>\n      <td>[-0.18150243, -0.24230756, -0.3336587, 0.34879...</td>\n      <td>[-0.14852196, 0.69629294, 0.30973893, 0.598406...</td>\n      <td>0</td>\n      <td>machine_nn01-38474877</td>\n      <td>{'end': None, 'start': 1823, 'obsolete': False...</td>\n      <td>[[machine_nn01-38474877, seed, machine_nn01]]</td>\n      <td>seed</td>\n      <td>{machine_nn01-38474877}</td>\n      <td>{machine_nn01-38474877}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>carcass_nn01-10177258</td>\n      <td>The dead body of a person or animal; but no lo...</td>\n      <td>The naked framework or ‘shell’ of a building b...</td>\n      <td>carcass_nn01</td>\n      <td>carcass</td>\n      <td>carcass_nn01-10177295</td>\n      <td>{'title': 'New Pract. Builder', 'author': 'P. ...</td>\n      <td>{'keyword': 'Carcase', 'full_text': 'Carcase o...</td>\n      <td>1823.0</td>\n      <td>Carcase of a Building, the naked walls, and th...</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>[0.6567496, -0.050804906, 0.31024605, 0.059706...</td>\n      <td>[0.41240987, 0.10217035, 0.48574266, 0.8627304...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1215</th>\n      <td>man_nn01-110479060</td>\n      <td>An adult male human being. Without explicit co...</td>\n      <td>A husband. Now chiefly English regional (north...</td>\n      <td>man_nn01</td>\n      <td>man</td>\n      <td>man_nn01-110479206</td>\n      <td>{'title': 'Four Years S. Afr.', 'author': 'C. ...</td>\n      <td>{'keyword': 'man', 'full_text': 'The wife brok...</td>\n      <td>1829.0</td>\n      <td>The wife broke out, ‘You lament a brother, and...</td>\n      <td>...</td>\n      <td>79.0</td>\n      <td>[-0.07307064, -0.31692728, 0.38834277, -0.2980...</td>\n      <td>[-0.20098017, 0.47577783, 0.013388823, -0.2808...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1216</th>\n      <td>person_nn01-30950985</td>\n      <td>An individual human being; a man, woman, or ch...</td>\n      <td>Law. An individual (natural person n.) or corp...</td>\n      <td>person_nn01</td>\n      <td>person</td>\n      <td>person_nn01-30951076</td>\n      <td>{'title': 'Daily News', 'author': None, 'gende...</td>\n      <td>{'keyword': 'persons', 'full_text': 'A Bill..e...</td>\n      <td>1900.0</td>\n      <td>A Bill..extending to juridical persons, that i...</td>\n      <td>...</td>\n      <td>31.0</td>\n      <td>[0.030711764, 0.28706473, 0.6596842, -0.132111...</td>\n      <td>[-0.42745396, 0.4621299, 0.34301567, 0.2193956...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1217</th>\n      <td>clay_nn01-9320873</td>\n      <td>A stiff viscous earth found, in many varieties...</td>\n      <td>Short for clay-pipe n. at  compounds 2 (colloq...</td>\n      <td>clay_nn01</td>\n      <td>clay</td>\n      <td>clay_nn01-9320896</td>\n      <td>{'title': 'Held in Bondage', 'author': '‘Ouida...</td>\n      <td>{'keyword': 'clays', 'full_text': 'Filthy bird...</td>\n      <td>1863.0</td>\n      <td>Filthy bird's-eye, smoked in clays.</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>[-0.016634814, 0.6912965, -0.18498293, -0.2104...</td>\n      <td>[-0.2833503, 0.80949837, -0.5981247, 0.4331013...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1218</th>\n      <td>case_nn02-10018131</td>\n      <td>A box, bag, or other receptacle, designed to c...</td>\n      <td>slang. A house, esp. one used as a brothel. Cf...</td>\n      <td>case_nn02</td>\n      <td>case</td>\n      <td>case_nn02-10018191</td>\n      <td>{'title': 'Mop Fair', 'author': 'A. M. Binstea...</td>\n      <td>{'keyword': 'case', 'full_text': 'They arrange...</td>\n      <td>1905.0</td>\n      <td>They arranges to stop ‘private’ in Brighton, a...</td>\n      <td>...</td>\n      <td>57.0</td>\n      <td>[0.16278893, -0.17927478, 0.34916735, -0.34717...</td>\n      <td>[0.3253876, 0.12327082, -0.077930324, 0.450299...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1220</th>\n      <td>man_nn01-110487579</td>\n      <td>An adult male human being. Without explicit co...</td>\n      <td>In Cumbria: a cairn marking a summit or promin...</td>\n      <td>man_nn01</td>\n      <td>man</td>\n      <td>man_nn01-110487624</td>\n      <td>{'title': 'Northern Affair', 'author': 'D. K. ...</td>\n      <td>{'keyword': 'man', 'full_text': 'Over the elep...</td>\n      <td>1964.0</td>\n      <td>Over the elephant rocks and under the lee of t...</td>\n      <td>...</td>\n      <td>55.0</td>\n      <td>[0.12908892, 0.1654679, -0.077464886, -0.44454...</td>\n      <td>[-0.4877532, 0.62317544, -0.4543179, -0.167910...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1135 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "df_train[df_train.label==\"0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             sense_id                                   lemma_definition  \\\n",
       "0  body_nn01-17170653  The complete physical form of a person or anim...   \n",
       "1  man_nn01-110482153  An adult male human being. Without explicit co...   \n",
       "2  body_nn01-17169813  The complete physical form of a person or anim...   \n",
       "\n",
       "                                          definition    word_id lemma  \\\n",
       "0  Particular technical uses. The part of a vehic...  body_nn01  body   \n",
       "1  As vocative or as int., introducing a remark o...   man_nn01   man   \n",
       "2  Contrasted with the soul. Cf. soul body n. at ...  body_nn01  body   \n",
       "\n",
       "          quotation_id                                             source  \\\n",
       "0  body_nn01-132916428  {'title': 'Material Handling Engin.', 'author'...   \n",
       "1   man_nn01-110482440  {'title': 'Shaela', 'author': 'R. Bulter', 'ge...   \n",
       "2   body_nn01-17169857  {'title': 'Ess. Man', 'author': 'A. Pope', 'ge...   \n",
       "\n",
       "                                                text    year  \\\n",
       "0  {'keyword': 'bodies', 'full_text': 'After car ...  1990.0   \n",
       "1  {'keyword': 'Min', 'full_text': 'Min A'm vexed...  1976.0   \n",
       "2  {'keyword': 'Body', 'full_text': 'All are but ...  1733.0   \n",
       "\n",
       "                                           full_text  ... keyword_offset  \\\n",
       "0  After car bodies are painted, they are moved i...  ...           10.0   \n",
       "1                         Min A'm vexed ta hear yun.  ...            0.0   \n",
       "2  All are but parts of one stupendous Whole, Who...  ...           49.0   \n",
       "\n",
       "                   vector_bert_base_-1,-2,-3,-4_mean  \\\n",
       "0  [1.2747291, 0.25178745, 0.69486666, 0.42832682...   \n",
       "1  [-0.10557328, 0.24347349, 0.731555, -0.4305202...   \n",
       "2  [0.8197431, 0.04237363, 0.6312159, -0.2658673,...   \n",
       "\n",
       "                       vector_blert_-1,-2,-3,-4_mean label   id daterange  \\\n",
       "0  [1.5054287, 1.1386966, 1.3405375, 0.8012274, -...     0  NaN       NaN   \n",
       "1  [-0.49209523, 0.7658461, 0.07512934, 0.0148925...     0  NaN       NaN   \n",
       "2  [0.60478234, 0.58020014, 0.053836707, -0.06571...     0  NaN       NaN   \n",
       "\n",
       "  provenance provenance_type relation_to_core_senses relation_to_seed_senses  \n",
       "0        NaN             NaN                     NaN                     NaN  \n",
       "1        NaN             NaN                     NaN                     NaN  \n",
       "2        NaN             NaN                     NaN                     NaN  \n",
       "\n",
       "[3 rows x 21 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sense_id</th>\n      <th>lemma_definition</th>\n      <th>definition</th>\n      <th>word_id</th>\n      <th>lemma</th>\n      <th>quotation_id</th>\n      <th>source</th>\n      <th>text</th>\n      <th>year</th>\n      <th>full_text</th>\n      <th>...</th>\n      <th>keyword_offset</th>\n      <th>vector_bert_base_-1,-2,-3,-4_mean</th>\n      <th>vector_blert_-1,-2,-3,-4_mean</th>\n      <th>label</th>\n      <th>id</th>\n      <th>daterange</th>\n      <th>provenance</th>\n      <th>provenance_type</th>\n      <th>relation_to_core_senses</th>\n      <th>relation_to_seed_senses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>body_nn01-17170653</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Particular technical uses. The part of a vehic...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-132916428</td>\n      <td>{'title': 'Material Handling Engin.', 'author'...</td>\n      <td>{'keyword': 'bodies', 'full_text': 'After car ...</td>\n      <td>1990.0</td>\n      <td>After car bodies are painted, they are moved i...</td>\n      <td>...</td>\n      <td>10.0</td>\n      <td>[1.2747291, 0.25178745, 0.69486666, 0.42832682...</td>\n      <td>[1.5054287, 1.1386966, 1.3405375, 0.8012274, -...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>man_nn01-110482153</td>\n      <td>An adult male human being. Without explicit co...</td>\n      <td>As vocative or as int., introducing a remark o...</td>\n      <td>man_nn01</td>\n      <td>man</td>\n      <td>man_nn01-110482440</td>\n      <td>{'title': 'Shaela', 'author': 'R. Bulter', 'ge...</td>\n      <td>{'keyword': 'Min', 'full_text': 'Min A'm vexed...</td>\n      <td>1976.0</td>\n      <td>Min A'm vexed ta hear yun.</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>[-0.10557328, 0.24347349, 0.731555, -0.4305202...</td>\n      <td>[-0.49209523, 0.7658461, 0.07512934, 0.0148925...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>body_nn01-17169813</td>\n      <td>The complete physical form of a person or anim...</td>\n      <td>Contrasted with the soul. Cf. soul body n. at ...</td>\n      <td>body_nn01</td>\n      <td>body</td>\n      <td>body_nn01-17169857</td>\n      <td>{'title': 'Ess. Man', 'author': 'A. Pope', 'ge...</td>\n      <td>{'keyword': 'Body', 'full_text': 'All are but ...</td>\n      <td>1733.0</td>\n      <td>All are but parts of one stupendous Whole, Who...</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>[0.8197431, 0.04237363, 0.6312159, -0.2658673,...</td>\n      <td>[0.60478234, 0.58020014, 0.053836707, -0.06571...</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 75
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
       "       'quotation_id', 'source', 'text', 'year', 'full_text', 'keyword',\n",
       "       'keyword_offset', 'vector_bert_base_-1,-2,-3,-4_mean',\n",
       "       'vector_blert_-1,-2,-3,-4_mean', 'label', 'id', 'daterange',\n",
       "       'provenance', 'provenance_type', 'relation_to_core_senses',\n",
       "       'relation_to_seed_senses'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enclose_keyword(row,enclose_token='\"'):\n",
    "    \"\"\"enclose keyword with specific token to point\n",
    "    learner towards to word it has to focus on\n",
    "    \"\"\"\n",
    "    sentence = ''\n",
    "    for i,c in enumerate(row.full_text):\n",
    "        if i == int(row.keyword_offset):\n",
    "            sentence+=enclose_token + ' '\n",
    "        elif i ==int(row.keyword_offset + len(row.keyword)):\n",
    "            sentence+= ' ' + enclose_token\n",
    "        sentence+=c\n",
    "    return sentence\n",
    "\n",
    "#def merge_quotation_gloss(row):\n",
    "#    out_string = '[GLOSS] '\n",
    "#    if row.definition:\n",
    "#        out_string+=row.definition\n",
    "#    out_string+=' [QUOT] '  \n",
    "#    if row.enclosed_quotation:\n",
    "#        out_string+=row.enclosed_quotation\n",
    "#    return out_string\n",
    "\n",
    "#def prep_train_text(row):\n",
    "#    out_string='[TAGET] '+row.keyword+' [TAGET] : '\n",
    "#    if row.definition:\n",
    "#        out_string+=row.definition\n",
    "#    out_string+=' [SEP] '  \n",
    "#    if row.enclosed_quotation:\n",
    "#        out_string+=row.enclosed_quotation\n",
    "#    return out_string\n",
    "\n",
    "#def prep_test_text(row):\n",
    "#    out_string='[TAGET] '+row.keyword+' [TAGET] : '\n",
    "#    if row.enclosed_quotation:\n",
    "#        out_string+=row.enclosed_quotation\n",
    "#    return out_string\n",
    "\n",
    "#def merge_quotation_keyword(row):\n",
    "#    out_string = '[TARGET] '\n",
    "#    if row.keyword:\n",
    "#        out_string+=row.keyword\n",
    "#    out_string+=' [QUOT] '  \n",
    "#    if row.enclosed_quotation:\n",
    "#        out_string+=row.enclosed_quotation\n",
    "#    return out_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_glossbert_format(df):\n",
    "    def gloss_string(row, definition):\n",
    "        out_string=''\n",
    "        if row.enclosed_quotation:\n",
    "            out_string+=row.enclosed_quotation\n",
    "        out_string+=' [SEP] '  \n",
    "        out_string+=row.keyword+': '\n",
    "        if row.definition:\n",
    "            out_string+=definition\n",
    "        return out_string\n",
    "\n",
    "    df['enclosed_quotations'] = df.apply(enclose_keyword, axis=1)\n",
    "    \n",
    "    rows = [] \n",
    "    for i,row in df.iterrows():\n",
    "        rows.append([gloss_string(row, row.definition), 1])\n",
    "        definitions = df[df.lemma==row.lemma].definition.unique()\n",
    "        for d in definitions:\n",
    "            if d != row.definition:\n",
    "                rows.append([gloss_string(row,d), 0])\n",
    "    \n",
    "    return rows\n",
    "\n",
    "df_gloss_train = to_glossbert_format(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: Particular technical uses. The part of a vehicle fitted to receive the load; spec. the part of a motor car in which driver and passengers sit, or the fuselage of an aeroplane. Cf. cart-body n. at  cart n. compounds 2, wide-body n.',\n",
       "  1],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: Contrasted with the soul. Cf. soul body n. at  soul n. compounds 4.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: Particular technical uses. The main part of a musical instrument, which in the case of traditional stringed instruments forms a resonating chamber.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: The complete physical form of a person or animal; the assemblage of parts, organs, and tissues that constitutes the whole material organism.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: A comprehensive and systematic collection of information, or of the details of any subject, esp. law; a textbook, a pandect. Usually with of.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: A corpse.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: The physical or mortal nature, state, or aspect of man. Frequently in in (the) body, out of (the) body and variants, sometimes contrasted with in spirit.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: More widely: a material thing, an object; something that has physical existence and extension in space.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: Cell Biology. Any of various normal or abnormal structures found within the cytoplasm or nucleus of a cell. Frequently with distinguishing word.',\n",
       "  0],\n",
       " ['After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color. [SEP] bodies: Originally: †size or bulk; quantity (obsolete). In later use: a quantity, mass, or area of something.',\n",
       "  0]]"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "df_gloss_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path('./data/training_data')\n",
    "path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_out_path = path / f\"{lemma}_{'_'.join(senses)}\"\n",
    "csv_out_path.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['enclosed_quotation'] = df_train.apply(enclose_keyword, axis=1)\n",
    "df_train['text'] = df_train.apply(prep_train_text, axis=1)\n",
    "df_train[['text','label']].to_csv(csv_out_path / \"train.csv\",index = False, sep='\\t')    \n",
    "df_val['enclosed_quotation'] = df_val.apply(enclose_keyword, axis=1)\n",
    "df_val['text'] = df_val.apply(prep_test_text, axis=1)\n",
    "df_val[['text','label']].to_csv(csv_out_path / \"dev.csv\",index = False, sep='\\t')        \n",
    "df_test['enclosed_quotation'] = df_test.apply(enclose_keyword, axis=1)\n",
    "df_test['text'] = df_test.apply(prep_test_text, axis=1)\n",
    "df_test[['text','label']].to_csv(csv_out_path / \"test.csv\",index = False, sep='\\t')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "387     [TAGET] Men [TAGET] : He canton'd out the Coun...\n",
       "1491    [TAGET] earths [TAGET] : Ley-grounds cannot be...\n",
       "1841    [TAGET] earth [TAGET] : It is well to see the ...\n",
       "1244    [TAGET] person [TAGET] : The administrator..ha...\n",
       "1809    [TAGET] earth [TAGET] : While I drove by in my...\n",
       "                              ...                        \n",
       "736     [TAGET] machines [TAGET] : ‘Anyone,’ declared,...\n",
       "610     [TAGET] machine [TAGET] : To each mortal perad...\n",
       "1612    [TAGET] body [TAGET] : The coffee, we know, st...\n",
       "1128    [TAGET] Personalities [TAGET] : Wisdom, Learni...\n",
       "1281    [TAGET] person [TAGET] : I'm a people [TARGET]...\n",
       "Name: text, Length: 383, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "df_test.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[TAGET] bodies [TAGET] : Particular technical uses. The part of a vehicle fitted to receive the load; spec. the part of a motor car in which driver and passengers sit, or the fuselage of an aeroplane. Cf. cart-body n. at  cart n. compounds 2, wide-body n. [SEP] After car [TARGET] bodies [TARGET] are painted, they are moved into storage to coordinate the production schedule with the number of bodies painted a specific color.'"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "df_train.iloc[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-14 17:14:29,725 Reading data from data/training_data/machine_machine_nn01-38474140\n",
      "2021-01-14 17:14:29,726 Train: data/training_data/machine_machine_nn01-38474140/train.csv\n",
      "2021-01-14 17:14:29,727 Dev: data/training_data/machine_machine_nn01-38474140/dev.csv\n",
      "2021-01-14 17:14:29,727 Test: data/training_data/machine_machine_nn01-38474140/test.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = csv_out_path\n",
    "\n",
    "# column format indicating which columns hold the text and label(s)\n",
    "column_name_map = {0: \"text\", 1: \"label\"}\n",
    "\n",
    "# load corpus containing training, test and dev data and if CSV has a header, you can skip it\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                         delimiter='\\t',    # tab-separated files\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-01-14 17:14:29,745 Computing label dictionary. Progress:\n",
      "100%|██████████| 1604/1604 [00:01<00:00, 1060.11it/s]2021-01-14 17:14:31,699 [b'0', b'1']\n",
      "Dictionary with 2 tags: 0, 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=2, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): {b'1': 10, b'0': 1}\n",
      "  (weight_tensor) tensor([1., 1.], device='cuda:0')\n",
      ")\"\n",
      "2021-01-14 17:14:33,683 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:33,684 Corpus: \"Corpus: 1221 train + 306 dev + 383 test sentences\"\n",
      "2021-01-14 17:14:33,684 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:33,685 Parameters:\n",
      "2021-01-14 17:14:33,685  - learning_rate: \"1e-05\"\n",
      "2021-01-14 17:14:33,686  - mini_batch_size: \"16\"\n",
      "2021-01-14 17:14:33,686  - patience: \"3\"\n",
      "2021-01-14 17:14:33,687  - anneal_factor: \"0.5\"\n",
      "2021-01-14 17:14:33,687  - max_epochs: \"10\"\n",
      "2021-01-14 17:14:33,688  - shuffle: \"True\"\n",
      "2021-01-14 17:14:33,688  - train_with_dev: \"False\"\n",
      "2021-01-14 17:14:33,689  - batch_growth_annealing: \"False\"\n",
      "2021-01-14 17:14:33,690 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:33,690 Model training base path: \"models/taggers/trec\"\n",
      "2021-01-14 17:14:33,691 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:33,691 Device: cuda:0\n",
      "2021-01-14 17:14:33,692 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:33,692 Embeddings storage mode: cpu\n",
      "2021-01-14 17:14:33,693 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:14:38,343 epoch 1 - iter 7/77 - loss 0.48898176 - samples/sec: 26.27 - lr: 0.000010\n",
      "2021-01-14 17:14:42,454 epoch 1 - iter 14/77 - loss 0.42082447 - samples/sec: 27.53 - lr: 0.000010\n",
      "2021-01-14 17:14:46,658 epoch 1 - iter 21/77 - loss 0.33773888 - samples/sec: 26.85 - lr: 0.000010\n",
      "2021-01-14 17:14:50,844 epoch 1 - iter 28/77 - loss 0.31560597 - samples/sec: 27.01 - lr: 0.000010\n",
      "2021-01-14 17:14:54,998 epoch 1 - iter 35/77 - loss 0.25972683 - samples/sec: 27.14 - lr: 0.000010\n",
      "2021-01-14 17:14:59,209 epoch 1 - iter 42/77 - loss 0.23569006 - samples/sec: 26.75 - lr: 0.000010\n",
      "2021-01-14 17:15:03,408 epoch 1 - iter 49/77 - loss 0.24985709 - samples/sec: 26.85 - lr: 0.000010\n",
      "2021-01-14 17:15:07,633 epoch 1 - iter 56/77 - loss 0.23229837 - samples/sec: 26.77 - lr: 0.000010\n",
      "2021-01-14 17:15:11,797 epoch 1 - iter 63/77 - loss 0.23326370 - samples/sec: 27.06 - lr: 0.000010\n",
      "2021-01-14 17:15:16,012 epoch 1 - iter 70/77 - loss 0.21914055 - samples/sec: 26.79 - lr: 0.000010\n",
      "2021-01-14 17:15:19,739 epoch 1 - iter 77/77 - loss 0.20128365 - samples/sec: 30.18 - lr: 0.000010\n",
      "2021-01-14 17:15:19,814 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:15:19,814 EPOCH 1 done: loss 0.2013 - lr 0.0000100\n",
      "2021-01-14 17:15:23,961 DEV : loss 0.33609411120414734 - score 0.9281\n",
      "2021-01-14 17:15:24,224 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-01-14 17:15:25,155 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:15:29,794 epoch 2 - iter 7/77 - loss 0.00740182 - samples/sec: 26.44 - lr: 0.000010\n",
      "2021-01-14 17:15:34,024 epoch 2 - iter 14/77 - loss 0.03390250 - samples/sec: 26.74 - lr: 0.000010\n",
      "2021-01-14 17:15:38,226 epoch 2 - iter 21/77 - loss 0.03571354 - samples/sec: 26.91 - lr: 0.000010\n",
      "2021-01-14 17:15:42,369 epoch 2 - iter 28/77 - loss 0.03136397 - samples/sec: 27.22 - lr: 0.000010\n",
      "2021-01-14 17:15:46,510 epoch 2 - iter 35/77 - loss 0.03331735 - samples/sec: 27.22 - lr: 0.000010\n",
      "2021-01-14 17:15:50,650 epoch 2 - iter 42/77 - loss 0.07917234 - samples/sec: 27.26 - lr: 0.000010\n",
      "2021-01-14 17:15:54,832 epoch 2 - iter 49/77 - loss 0.07227532 - samples/sec: 26.94 - lr: 0.000010\n",
      "2021-01-14 17:15:59,093 epoch 2 - iter 56/77 - loss 0.06382573 - samples/sec: 26.50 - lr: 0.000010\n",
      "2021-01-14 17:16:03,303 epoch 2 - iter 63/77 - loss 0.08917253 - samples/sec: 26.79 - lr: 0.000010\n",
      "2021-01-14 17:16:07,583 epoch 2 - iter 70/77 - loss 0.08041374 - samples/sec: 26.33 - lr: 0.000010\n",
      "2021-01-14 17:16:11,374 epoch 2 - iter 77/77 - loss 0.08118116 - samples/sec: 29.72 - lr: 0.000010\n",
      "2021-01-14 17:16:11,437 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:16:11,438 EPOCH 2 done: loss 0.0812 - lr 0.0000100\n",
      "2021-01-14 17:16:15,649 DEV : loss 0.5065702795982361 - score 0.9248\n",
      "2021-01-14 17:16:15,909 BAD EPOCHS (no improvement): 1\n",
      "2021-01-14 17:16:15,910 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:16:20,491 epoch 3 - iter 7/77 - loss 0.00894024 - samples/sec: 26.72 - lr: 0.000010\n",
      "2021-01-14 17:16:24,744 epoch 3 - iter 14/77 - loss 0.04298888 - samples/sec: 26.62 - lr: 0.000010\n",
      "2021-01-14 17:16:29,099 epoch 3 - iter 21/77 - loss 0.05707598 - samples/sec: 25.96 - lr: 0.000010\n",
      "2021-01-14 17:16:33,430 epoch 3 - iter 28/77 - loss 0.04700577 - samples/sec: 26.10 - lr: 0.000010\n",
      "2021-01-14 17:16:37,615 epoch 3 - iter 35/77 - loss 0.03774460 - samples/sec: 26.92 - lr: 0.000010\n",
      "2021-01-14 17:16:41,848 epoch 3 - iter 42/77 - loss 0.03161711 - samples/sec: 26.63 - lr: 0.000010\n",
      "2021-01-14 17:16:46,019 epoch 3 - iter 49/77 - loss 0.02749447 - samples/sec: 27.00 - lr: 0.000010\n",
      "2021-01-14 17:16:50,152 epoch 3 - iter 56/77 - loss 0.02414880 - samples/sec: 27.36 - lr: 0.000010\n",
      "2021-01-14 17:16:54,291 epoch 3 - iter 63/77 - loss 0.02319205 - samples/sec: 27.22 - lr: 0.000010\n",
      "2021-01-14 17:16:58,450 epoch 3 - iter 70/77 - loss 0.02129739 - samples/sec: 27.15 - lr: 0.000010\n",
      "2021-01-14 17:17:02,224 epoch 3 - iter 77/77 - loss 0.01944040 - samples/sec: 29.79 - lr: 0.000010\n",
      "2021-01-14 17:17:02,272 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:17:02,273 EPOCH 3 done: loss 0.0194 - lr 0.0000100\n",
      "2021-01-14 17:17:06,524 DEV : loss 0.49905064702033997 - score 0.9216\n",
      "2021-01-14 17:17:06,786 BAD EPOCHS (no improvement): 2\n",
      "2021-01-14 17:17:06,787 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:17:11,358 epoch 4 - iter 7/77 - loss 0.00185599 - samples/sec: 26.75 - lr: 0.000010\n",
      "2021-01-14 17:17:15,541 epoch 4 - iter 14/77 - loss 0.00136404 - samples/sec: 27.04 - lr: 0.000010\n",
      "2021-01-14 17:17:19,712 epoch 4 - iter 21/77 - loss 0.00128906 - samples/sec: 27.07 - lr: 0.000010\n",
      "2021-01-14 17:17:23,840 epoch 4 - iter 28/77 - loss 0.00118582 - samples/sec: 27.40 - lr: 0.000010\n",
      "2021-01-14 17:17:28,020 epoch 4 - iter 35/77 - loss 0.00106619 - samples/sec: 26.98 - lr: 0.000010\n",
      "2021-01-14 17:17:32,295 epoch 4 - iter 42/77 - loss 0.00094899 - samples/sec: 26.41 - lr: 0.000010\n",
      "2021-01-14 17:17:36,522 epoch 4 - iter 49/77 - loss 0.00087282 - samples/sec: 26.66 - lr: 0.000010\n",
      "2021-01-14 17:17:40,684 epoch 4 - iter 56/77 - loss 0.00097088 - samples/sec: 27.12 - lr: 0.000010\n",
      "2021-01-14 17:17:44,912 epoch 4 - iter 63/77 - loss 0.00087886 - samples/sec: 26.69 - lr: 0.000010\n",
      "2021-01-14 17:17:49,112 epoch 4 - iter 70/77 - loss 0.00110282 - samples/sec: 26.91 - lr: 0.000010\n",
      "2021-01-14 17:17:52,950 epoch 4 - iter 77/77 - loss 0.00101001 - samples/sec: 29.33 - lr: 0.000010\n",
      "2021-01-14 17:17:53,013 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:17:53,014 EPOCH 4 done: loss 0.0010 - lr 0.0000100\n",
      "2021-01-14 17:17:57,333 DEV : loss 0.5981439352035522 - score 0.9216\n",
      "2021-01-14 17:17:57,595 BAD EPOCHS (no improvement): 3\n",
      "2021-01-14 17:17:57,596 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:18:02,196 epoch 5 - iter 7/77 - loss 0.00060182 - samples/sec: 26.72 - lr: 0.000010\n",
      "2021-01-14 17:18:06,460 epoch 5 - iter 14/77 - loss 0.00037103 - samples/sec: 26.48 - lr: 0.000010\n",
      "2021-01-14 17:18:10,664 epoch 5 - iter 21/77 - loss 0.00028840 - samples/sec: 26.89 - lr: 0.000010\n",
      "2021-01-14 17:18:14,811 epoch 5 - iter 28/77 - loss 0.00025692 - samples/sec: 27.23 - lr: 0.000010\n",
      "2021-01-14 17:18:18,940 epoch 5 - iter 35/77 - loss 0.00024187 - samples/sec: 27.30 - lr: 0.000010\n",
      "2021-01-14 17:18:23,111 epoch 5 - iter 42/77 - loss 0.00021889 - samples/sec: 27.08 - lr: 0.000010\n",
      "2021-01-14 17:18:27,299 epoch 5 - iter 49/77 - loss 0.00035217 - samples/sec: 26.95 - lr: 0.000010\n",
      "2021-01-14 17:18:31,425 epoch 5 - iter 56/77 - loss 0.00032686 - samples/sec: 27.30 - lr: 0.000010\n",
      "2021-01-14 17:18:35,586 epoch 5 - iter 63/77 - loss 0.00029595 - samples/sec: 27.13 - lr: 0.000010\n",
      "2021-01-14 17:18:39,774 epoch 5 - iter 70/77 - loss 0.00027235 - samples/sec: 26.91 - lr: 0.000010\n",
      "2021-01-14 17:18:43,540 epoch 5 - iter 77/77 - loss 0.00028631 - samples/sec: 29.89 - lr: 0.000010\n",
      "2021-01-14 17:18:43,601 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:18:43,602 EPOCH 5 done: loss 0.0003 - lr 0.0000100\n",
      "2021-01-14 17:18:46,910 DEV : loss 0.6656511425971985 - score 0.9248\n",
      "Epoch     5: reducing learning rate of group 0 to 5.0000e-06.\n",
      "2021-01-14 17:18:47,170 BAD EPOCHS (no improvement): 4\n",
      "2021-01-14 17:18:47,171 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:18:53,782 epoch 6 - iter 7/77 - loss 0.00022932 - samples/sec: 25.95 - lr: 0.000005\n",
      "2021-01-14 17:18:57,949 epoch 6 - iter 14/77 - loss 0.00016531 - samples/sec: 27.13 - lr: 0.000005\n",
      "2021-01-14 17:19:02,280 epoch 6 - iter 21/77 - loss 0.00022724 - samples/sec: 25.99 - lr: 0.000005\n",
      "2021-01-14 17:19:06,568 epoch 6 - iter 28/77 - loss 0.00026307 - samples/sec: 26.27 - lr: 0.000005\n",
      "2021-01-14 17:19:10,654 epoch 6 - iter 35/77 - loss 0.00023027 - samples/sec: 27.57 - lr: 0.000005\n",
      "2021-01-14 17:19:14,851 epoch 6 - iter 42/77 - loss 0.00021121 - samples/sec: 26.89 - lr: 0.000005\n",
      "2021-01-14 17:19:19,029 epoch 6 - iter 49/77 - loss 0.00019923 - samples/sec: 26.94 - lr: 0.000005\n",
      "2021-01-14 17:19:23,229 epoch 6 - iter 56/77 - loss 0.00018661 - samples/sec: 26.87 - lr: 0.000005\n",
      "2021-01-14 17:19:27,356 epoch 6 - iter 63/77 - loss 0.00017462 - samples/sec: 27.26 - lr: 0.000005\n",
      "2021-01-14 17:19:31,517 epoch 6 - iter 70/77 - loss 0.00016146 - samples/sec: 27.04 - lr: 0.000005\n",
      "2021-01-14 17:19:35,455 epoch 6 - iter 77/77 - loss 0.00015018 - samples/sec: 28.60 - lr: 0.000005\n",
      "2021-01-14 17:19:35,526 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:19:35,527 EPOCH 6 done: loss 0.0002 - lr 0.0000050\n",
      "2021-01-14 17:19:39,223 DEV : loss 0.6893778443336487 - score 0.9248\n",
      "2021-01-14 17:19:39,484 BAD EPOCHS (no improvement): 1\n",
      "2021-01-14 17:19:39,486 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:19:44,844 epoch 7 - iter 7/77 - loss 0.00019211 - samples/sec: 27.26 - lr: 0.000005\n",
      "2021-01-14 17:19:49,028 epoch 7 - iter 14/77 - loss 0.00066268 - samples/sec: 26.98 - lr: 0.000005\n",
      "2021-01-14 17:19:53,253 epoch 7 - iter 21/77 - loss 0.00053614 - samples/sec: 26.67 - lr: 0.000005\n",
      "2021-01-14 17:19:57,430 epoch 7 - iter 28/77 - loss 0.00043514 - samples/sec: 27.03 - lr: 0.000005\n",
      "2021-01-14 17:20:01,594 epoch 7 - iter 35/77 - loss 0.00036258 - samples/sec: 27.03 - lr: 0.000005\n",
      "2021-01-14 17:20:05,829 epoch 7 - iter 42/77 - loss 0.00031573 - samples/sec: 26.60 - lr: 0.000005\n",
      "2021-01-14 17:20:10,013 epoch 7 - iter 49/77 - loss 0.00028645 - samples/sec: 26.94 - lr: 0.000005\n",
      "2021-01-14 17:20:14,238 epoch 7 - iter 56/77 - loss 0.00025793 - samples/sec: 26.67 - lr: 0.000005\n",
      "2021-01-14 17:20:18,381 epoch 7 - iter 63/77 - loss 0.00023890 - samples/sec: 27.16 - lr: 0.000005\n",
      "2021-01-14 17:20:22,569 epoch 7 - iter 70/77 - loss 0.00021868 - samples/sec: 26.92 - lr: 0.000005\n",
      "2021-01-14 17:20:26,365 epoch 7 - iter 77/77 - loss 0.00020789 - samples/sec: 29.64 - lr: 0.000005\n",
      "2021-01-14 17:20:26,443 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:20:26,443 EPOCH 7 done: loss 0.0002 - lr 0.0000050\n",
      "2021-01-14 17:20:29,751 DEV : loss 0.6999250054359436 - score 0.9248\n",
      "2021-01-14 17:20:30,015 BAD EPOCHS (no improvement): 2\n",
      "2021-01-14 17:20:30,016 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:20:34,509 epoch 8 - iter 7/77 - loss 0.00007416 - samples/sec: 27.22 - lr: 0.000005\n",
      "2021-01-14 17:20:39,619 epoch 8 - iter 14/77 - loss 0.00005522 - samples/sec: 26.82 - lr: 0.000005\n",
      "2021-01-14 17:20:43,900 epoch 8 - iter 21/77 - loss 0.00006253 - samples/sec: 26.35 - lr: 0.000005\n",
      "2021-01-14 17:20:48,020 epoch 8 - iter 28/77 - loss 0.00015550 - samples/sec: 27.36 - lr: 0.000005\n",
      "2021-01-14 17:20:52,243 epoch 8 - iter 35/77 - loss 0.00013324 - samples/sec: 26.66 - lr: 0.000005\n",
      "2021-01-14 17:20:56,397 epoch 8 - iter 42/77 - loss 0.00012891 - samples/sec: 27.08 - lr: 0.000005\n",
      "2021-01-14 17:21:00,493 epoch 8 - iter 49/77 - loss 0.00012485 - samples/sec: 27.50 - lr: 0.000005\n",
      "2021-01-14 17:21:04,731 epoch 8 - iter 56/77 - loss 0.00014117 - samples/sec: 26.59 - lr: 0.000005\n",
      "2021-01-14 17:21:08,909 epoch 8 - iter 63/77 - loss 0.00013634 - samples/sec: 26.95 - lr: 0.000005\n",
      "2021-01-14 17:21:13,121 epoch 8 - iter 70/77 - loss 0.00012635 - samples/sec: 26.74 - lr: 0.000005\n",
      "2021-01-14 17:21:16,967 epoch 8 - iter 77/77 - loss 0.00012047 - samples/sec: 29.24 - lr: 0.000005\n",
      "2021-01-14 17:21:17,026 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:21:17,027 EPOCH 8 done: loss 0.0001 - lr 0.0000050\n",
      "2021-01-14 17:21:20,598 DEV : loss 0.7107362747192383 - score 0.9248\n",
      "2021-01-14 17:21:20,864 BAD EPOCHS (no improvement): 3\n",
      "2021-01-14 17:21:20,865 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:21:26,269 epoch 9 - iter 7/77 - loss 0.00002916 - samples/sec: 26.76 - lr: 0.000005\n",
      "2021-01-14 17:21:30,543 epoch 9 - iter 14/77 - loss 0.00006615 - samples/sec: 26.39 - lr: 0.000005\n",
      "2021-01-14 17:21:34,808 epoch 9 - iter 21/77 - loss 0.00006364 - samples/sec: 26.48 - lr: 0.000005\n",
      "2021-01-14 17:21:38,963 epoch 9 - iter 28/77 - loss 0.00013939 - samples/sec: 27.14 - lr: 0.000005\n",
      "2021-01-14 17:21:43,165 epoch 9 - iter 35/77 - loss 0.00012621 - samples/sec: 26.86 - lr: 0.000005\n",
      "2021-01-14 17:21:47,317 epoch 9 - iter 42/77 - loss 0.00012101 - samples/sec: 27.09 - lr: 0.000005\n",
      "2021-01-14 17:21:51,532 epoch 9 - iter 49/77 - loss 0.00018356 - samples/sec: 26.78 - lr: 0.000005\n",
      "2021-01-14 17:21:56,114 epoch 9 - iter 56/77 - loss 0.00016344 - samples/sec: 26.01 - lr: 0.000005\n",
      "2021-01-14 17:22:00,349 epoch 9 - iter 63/77 - loss 0.00015143 - samples/sec: 26.58 - lr: 0.000005\n",
      "2021-01-14 17:22:04,591 epoch 9 - iter 70/77 - loss 0.00013992 - samples/sec: 26.55 - lr: 0.000005\n",
      "2021-01-14 17:22:08,380 epoch 9 - iter 77/77 - loss 0.00012958 - samples/sec: 29.74 - lr: 0.000005\n",
      "2021-01-14 17:22:08,443 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:22:08,444 EPOCH 9 done: loss 0.0001 - lr 0.0000050\n",
      "2021-01-14 17:22:11,739 DEV : loss 0.7207703590393066 - score 0.9248\n",
      "Epoch     9: reducing learning rate of group 0 to 2.5000e-06.\n",
      "2021-01-14 17:22:12,003 BAD EPOCHS (no improvement): 4\n",
      "2021-01-14 17:22:12,004 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:22:16,599 epoch 10 - iter 7/77 - loss 0.00004176 - samples/sec: 26.48 - lr: 0.000003\n",
      "2021-01-14 17:22:21,730 epoch 10 - iter 14/77 - loss 0.00004900 - samples/sec: 26.15 - lr: 0.000003\n",
      "2021-01-14 17:22:25,925 epoch 10 - iter 21/77 - loss 0.00005921 - samples/sec: 26.94 - lr: 0.000003\n",
      "2021-01-14 17:22:30,112 epoch 10 - iter 28/77 - loss 0.00005456 - samples/sec: 26.94 - lr: 0.000003\n",
      "2021-01-14 17:22:34,389 epoch 10 - iter 35/77 - loss 0.00004909 - samples/sec: 26.34 - lr: 0.000003\n",
      "2021-01-14 17:22:38,546 epoch 10 - iter 42/77 - loss 0.00004503 - samples/sec: 27.15 - lr: 0.000003\n",
      "2021-01-14 17:22:42,757 epoch 10 - iter 49/77 - loss 0.00004776 - samples/sec: 26.71 - lr: 0.000003\n",
      "2021-01-14 17:22:46,803 epoch 10 - iter 56/77 - loss 0.00004461 - samples/sec: 27.81 - lr: 0.000003\n",
      "2021-01-14 17:22:51,063 epoch 10 - iter 63/77 - loss 0.00004382 - samples/sec: 26.47 - lr: 0.000003\n",
      "2021-01-14 17:22:55,173 epoch 10 - iter 70/77 - loss 0.00005728 - samples/sec: 27.40 - lr: 0.000003\n",
      "2021-01-14 17:22:58,941 epoch 10 - iter 77/77 - loss 0.00005446 - samples/sec: 29.83 - lr: 0.000003\n",
      "2021-01-14 17:22:58,988 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:22:58,989 EPOCH 10 done: loss 0.0001 - lr 0.0000025\n",
      "2021-01-14 17:23:02,304 DEV : loss 0.7250329852104187 - score 0.9248\n",
      "2021-01-14 17:23:02,567 BAD EPOCHS (no improvement): 1\n",
      "2021-01-14 17:23:04,650 ----------------------------------------------------------------------------------------------------\n",
      "2021-01-14 17:23:04,651 Testing using best model ...\n",
      "2021-01-14 17:23:04,653 loading file models/taggers/trec/best-model.pt\n",
      "2021-01-14 17:23:09,692 \t0.9295\n",
      "2021-01-14 17:23:09,693 \n",
      "Results:\n",
      "- F-score (micro) 0.9295\n",
      "- F-score (macro) 0.4817\n",
      "- Accuracy 0.9295\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9295    1.0000    0.9635       356\n",
      "           1     0.0000    0.0000    0.0000        27\n",
      "\n",
      "   micro avg     0.9295    0.9295    0.9295       383\n",
      "   macro avg     0.4648    0.5000    0.4817       383\n",
      "weighted avg     0.8640    0.9295    0.8955       383\n",
      " samples avg     0.9295    0.9295    0.9295       383\n",
      "\n",
      "2021-01-14 17:23:09,694 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'test_score': 0.9295,\n",
       " 'dev_score_history': [0.9281,\n",
       "  0.9248,\n",
       "  0.9216,\n",
       "  0.9216,\n",
       "  0.9248,\n",
       "  0.9248,\n",
       "  0.9248,\n",
       "  0.9248,\n",
       "  0.9248,\n",
       "  0.9248],\n",
       " 'train_loss_history': [0.20128365170646023,\n",
       "  0.08118115926717782,\n",
       "  0.019440397426679537,\n",
       "  0.0010100115429271352,\n",
       "  0.00028631362048062414,\n",
       "  0.00015017583772733613,\n",
       "  0.0002078855192506468,\n",
       "  0.00012047414655809278,\n",
       "  0.00012958204591429078,\n",
       "  5.446238951249556e-05],\n",
       " 'dev_loss_history': [0.33609411120414734,\n",
       "  0.5065702795982361,\n",
       "  0.49905064702033997,\n",
       "  0.5981439352035522,\n",
       "  0.6656511425971985,\n",
       "  0.6893778443336487,\n",
       "  0.6999250054359436,\n",
       "  0.7107362747192383,\n",
       "  0.7207703590393066,\n",
       "  0.7250329852104187]}"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "\n",
    "# 3. initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)\n",
    "\n",
    "# 4. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict, loss_weights={b\"1\":10, b\"0\":1}) # loss_weights={\"1\":10, \"0\":1}\n",
    "\n",
    "# 5. initialize the text classifier trainer with Adam optimizer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)\n",
    "\n",
    "# 6. start the training\n",
    "trainer.train('models/taggers/trec',\n",
    "              learning_rate=1e-5, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=10, # terminate after 5 epochs\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}