{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run `eval_sense` in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install `parhugin`** by:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/kasra-hosseini/parhugin.git\n",
    "```\n",
    "\n",
    "or follow the instructions [here](https://github.com/kasra-hosseini/parhugin#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from utils import nlp_tools\n",
    "from gensim.models import Word2Vec\n",
    "from utils.classificaton_utils import binarize,generate_definition_df\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from parhugin import multiFunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sense(lemma,pos,sense,start=1760,end=1920,train_on_dev=True):\n",
    "\n",
    "    df_train, df_val, df_test = binarize(lemma,\n",
    "                pos,\n",
    "                {sense}, \n",
    "                relations,\n",
    "                strict_filter=True,\n",
    "                start=start,\n",
    "                end=end,\n",
    "                eval_mode=eval_mode)\n",
    "\n",
    "    # no quotations for sense and timeframe\n",
    "    if df_train is None:\n",
    "        return None\n",
    "    \n",
    "    if train_on_dev:\n",
    "        df_train = pd.concat([df_train, df_val], axis=0)\n",
    "\n",
    "    df_train[\"nlp_full_text\"] = df_train.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "    df_val[\"nlp_full_text\"] = df_val.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "    df_test[\"nlp_full_text\"] = df_test.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "    # random \n",
    "    df_test[\"random\"] = df_test.apply (lambda row: wsd.random_predict(), axis=1)\n",
    "\n",
    "    # retrieve and process definitions            \n",
    "    df_selected_senses = generate_definition_df(df_train,lemma,eval_mode=eval_mode)\n",
    "    df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n",
    "\n",
    "    # token overlap\n",
    "    df_test[\"def_tok_overlap_ranking\"] = df_test.apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "    # spacy sentence embeddings\n",
    "    df_test[\"sent_embedding\"] = df_test.apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "    #w2v lesk\n",
    "    # Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "    df_test[\"w2v_lesk_ranking\"] = df_test.apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], df_selected_senses, wemb_model), axis=1)\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we first define the serial version of the run\n",
    "# It combines both eval_sense and other parts to output the results\n",
    "\n",
    "def serial_run(lemma, pos, sense, eval_mode, relations, start=1760, end=1920, train_on_dev=True):\n",
    "    df_test = eval_sense(lemma,\n",
    "                         pos,\n",
    "                         sense,\n",
    "                         start=1760,\n",
    "                         end=1920,\n",
    "                         train_on_dev=True)\n",
    "\n",
    "    results_path = os.path.join('results', f\"{lemma}_{pos}\", eval_mode)\n",
    "    results_filename = sense + \"~\" + \"+\".join(sorted(relations)) + \".csv\"\n",
    "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # IF df_test is None, create an empty DataFrame\n",
    "    if not isinstance(df_test, type(None)):\n",
    "        out_df = df_test.filter(['id_x','label','random','def_tok_overlap_ranking', \n",
    "                                 'sent_embedding', 'w2v_lesk_ranking'], axis=1)\n",
    "    else:\n",
    "        out_df = pd.DataFrame()\n",
    "\n",
    "    out_df.to_csv(os.path.join(results_path, results_filename), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a list of all runs, see list_jobs\n",
    "\n",
    "words = [[\"machine\",\"NN\"]]\n",
    "#words = [[\"anger\",\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],[\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],[\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],[\"technology\",\"NN\"],[\"woman\",\"NN\"]]\n",
    "\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "list_jobs = []\n",
    "for lemma, pos in words:\n",
    "    quotations_path = f\"./data/sfrel_quotations_{lemma}_{pos}.pickle\"\n",
    "    lemma_senses = pd.read_pickle(f'./data/lemma_senses_{lemma}_{pos}.pickle')\n",
    "    \n",
    "    # not sure what is this thing\n",
    "    idx = \"01\"\n",
    "    \n",
    "    senses = set(lemma_senses[lemma_senses.word_id==f'{lemma}_{pos.lower()}{idx}'].id)\n",
    "    \n",
    "    for sense in senses:\n",
    "        list_jobs.append([serial_run, (lemma, pos, sense, eval_mode, relations, 1760, 1920, True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<function __main__.serial_run(lemma, pos, sense, eval_mode, relations, start=1760, end=1920, train_on_dev=True)>,\n",
       "  ('machine',\n",
       "   'NN',\n",
       "   'machine_nn01-38475046',\n",
       "   'lemma_etal',\n",
       "   ['seed', 'synonym'],\n",
       "   1760,\n",
       "   1920,\n",
       "   True)],\n",
       " [<function __main__.serial_run(lemma, pos, sense, eval_mode, relations, start=1760, end=1920, train_on_dev=True)>,\n",
       "  ('machine',\n",
       "   'NN',\n",
       "   'machine_nn01-38474548',\n",
       "   'lemma_etal',\n",
       "   ['seed', 'synonym'],\n",
       "   1760,\n",
       "   1920,\n",
       "   True)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_jobs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point, `list_jobs` contains a list of jobs to be run in parallel, e.g.: \n",
    "\n",
    "```python\n",
    "[   \n",
    "    [serial_run, (lemma1, pos1, ...)],\n",
    "    [serial_run, (lemma2, pos2, ...)],  \n",
    "    [serial_run, (...)],\n",
    "    ...\n",
    "] \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] #requested processes: 8\n"
     ]
    }
   ],
   "source": [
    "from parhugin import multiFunc\n",
    "\n",
    "# num_req_p: number of processes to be run in parallel\n",
    "myprocs = multiFunc(num_req_p=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#requested processed: 8\n",
      "#jobs: 26\n"
     ]
    }
   ],
   "source": [
    "# Add the list of jobs\n",
    "myprocs.add_list_jobs(list_jobs)\n",
    "print(myprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] start job-0\n",
      "[INFO] start job-1\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "[INFO] start job-2\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date =\n",
      "\n",
      "# of seeds selected  5171\n",
      " \n",
      "# of synonyms selected 9 \n",
      "# of branches selected[INFO] start job-3\n",
      " 0\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "[INFO] start job-4\n",
      "\n",
      "\n",
      "# of seeds selected 1Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object') \n",
      "# senses before filtering by date =\n",
      "# of synonyms selected  51725\n",
      " \n",
      "# of branches selected 0\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms[INFO] start job-5\n",
      " 310 \n",
      "# of branch senses 0\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "[INFO] start job-6\n",
      "\n",
      "\n",
      "# of seeds selectedIndex(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date =# senses after filtering by date =   1517352 \n",
      "\n",
      "# of synonyms selected\n",
      " 1 \n",
      "# of branches selected\n",
      "\n",
      "# of seed senses  022\n",
      " \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "# senses after filtering by date =[INFO] start job-7\n",
      " 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 65 \n",
      "# of branches selected 0\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "\n",
      "\n",
      "# of seeds selected 1 # senses after filtering by date = \n",
      "# of synonyms selected 3520\n",
      " \n",
      "# of branches selected 0\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date =Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object') \n",
      "352\n",
      "# senses before filtering by date = \n",
      "\n",
      "# of seed senses517 \n",
      "22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses\n",
      "\n",
      "# of seeds selected 22  0\n",
      "# of synonyms  310\n",
      "# of synonyms selected \n",
      "# of branch senses 0  0\n",
      "# of branches selected\n",
      " 0\n",
      "\n",
      "\n",
      "# of seeds selected 0 \n",
      "# of synonyms selected 8 \n",
      "# of branches selected 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 10 \n",
      "# of branches selected 0\n",
      "\n",
      "There are not quotations available, given this sense-id and time-frame.\n",
      "[INFO] start job-8\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "Using lemma_etal as evaluation mode.\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 4 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 4 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/tasks/wsd.py:42: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  definition_df[\"sent_embedding\"] = definition_df.apply (lambda row: sent.similarity(row[\"nlp_definition\"]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] start job-10\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 38 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-11\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 8 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-12\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 0 \n",
      "# of synonyms selected 14 \n",
      "# of branches selected 0\n",
      "[INFO] start job-13\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 2 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/tasks/wsd.py:42: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  definition_df[\"sent_embedding\"] = definition_df.apply (lambda row: sent.similarity(row[\"nlp_definition\"]), axis=1)\n",
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-14\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 6 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-15\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 6 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-16\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 2 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-17\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 33 \n",
      "# of branches selected 0\n",
      "[INFO] start job-18\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 0 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-19\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 0 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/tasks/wsd.py:42: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  definition_df[\"sent_embedding\"] = definition_df.apply (lambda row: sent.similarity(row[\"nlp_definition\"]), axis=1)\n",
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-20\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 3 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-21\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 15 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-22\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 4 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/tasks/wsd.py:42: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  definition_df[\"sent_embedding\"] = definition_df.apply (lambda row: sent.similarity(row[\"nlp_definition\"]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] start job-23\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 0 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n",
      "[INFO] start job-24\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 24 \n",
      "# of branches selected 0\n",
      "[INFO] start job-25\n",
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n",
      "       'quotation_id', 'source', 'text', 'year'],\n",
      "      dtype='object')\n",
      "# senses before filtering by date = 517\n",
      "# senses after filtering by date = 352\n",
      "\n",
      "\n",
      "# of seed senses 22 \n",
      "# of synonyms 310 \n",
      "# of branch senses 0\n",
      "\n",
      "\n",
      "# of seeds selected 0 \n",
      "# of synonyms selected 29 \n",
      "# of branches selected 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/utils/classificaton_utils.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected_senses['definition'] = df_selected_senses.apply(merge_definitions, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khosseini/myJobs/ATI/Projects/2019/HistoricalDictionaryExpansion/tasks/wsd.py:42: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  definition_df[\"sent_embedding\"] = definition_df.apply (lambda row: sent.similarity(row[\"nlp_definition\"]), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "#finished jobs: 26\n",
      "#running jobs: 0\n",
      "#remained jobs: 0\n",
      "==========\n",
      "Total time: 839.086893081665\n",
      "==========\n",
      "List of exceptions\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "myprocs.run_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Collect a list of all runs, see list_jobs\n",
    "\n",
    "# # this is the first for loop to parallelise\n",
    "# words = [[\"machine\",\"NN\"]]\n",
    "# #words = [[\"anger\",\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],[\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],[\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],[\"technology\",\"NN\"],[\"woman\",\"NN\"]]\n",
    "\n",
    "# relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "# eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "\n",
    "# wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "# list_jobs = []\n",
    "# for lemma, pos in words:\n",
    "#     quotations_path = f\"./data/sfrel_quotations_{lemma}_{pos}.pickle\"\n",
    "#     lemma_senses = pd.read_pickle(f'./data/lemma_senses_{lemma}_{pos}.pickle')\n",
    "    \n",
    "#     # not sure what is this thing\n",
    "#     idx = \"01\"\n",
    "    \n",
    "#     senses = set(lemma_senses[lemma_senses.word_id==f'{lemma}_{pos.lower()}{idx}'].id)\n",
    "    \n",
    "#     for sense in senses:\n",
    "#         serial_run(lemma, pos, sense, eval_mode, relations, 1760, 1920, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
