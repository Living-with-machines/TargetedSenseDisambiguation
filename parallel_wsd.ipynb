{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run `eval_sense` in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install `parhugin`** by:\n",
    "\n",
    "```bash\n",
    "pip install git+https://github.com/kasra-hosseini/parhugin.git\n",
    "```\n",
    "\n",
    "or follow the instructions [here](https://github.com/kasra-hosseini/parhugin#installation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from utils import nlp_tools, wsd\n",
    "from parhugin import multiFunc\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.dataset_download import harvest_data_from_extended_senses\n",
    "from utils.classificaton_utils import binarize,generate_definition_df, vectorize_target_expressions\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "tqdm.pandas()"
   ]
  },
  {
   "source": [
    "# Prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# import API credentials\n",
    "with open('oed_experiments/oed_credentials.json') as f:\n",
    "    auth = json.load(f)\n",
    "\n",
    " \n",
    "lemma_pos = [['anger',\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],[\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],[\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],['woman','NN']]\n",
    "#[\"technology\",\"NN\"] #Â got an error with technology\n",
    "\n",
    "embedding_methods = {'bert_base': {\"path\":'bert-base-uncased',\n",
    "                                   'layers':'-1,-2,-3,-4',\n",
    "                                   'pooling_operation':'mean'},\n",
    "                    'blert_base': {\"path\":'/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002',\n",
    "                                   'layers':'-1,-2,-3,-4',\n",
    "                                   'pooling_operation':'mean'},\n",
    "                    'bert_1850':{\"path\":\"/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001\", \n",
    "                                   'layers':'-1,-2,-3,-4',\n",
    "                                   'pooling_operation':'mean'}\n",
    "                                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=22627.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0433f06843df43beaf27f9feb3f55c4a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=22627.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38d6ed86a4fd46c79d497bcc3627e206"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=22627.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26ff211247d848a6b8c0be0920bd848e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "[WARNING] 'vectors' variable is empty. Return None.\n",
      "\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_base settings\n",
      "{'path': 'bert-base-uncased', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from blert_base settings\n",
      "{'path': '/deezy_datadrive/kaspar-playground/bert_model/FT_bert_base_uncased_all_books_v002', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n",
      "Dataframe alread contains vectors from bert_1850 settings\n",
      "{'path': '/datadrive/khosseini/LM_with_bert_MOVED_to_another_VM_REMOVE_FROM_NOVEMBER/models/bert/FT_bert_base_uncased_before_1850_v001', 'layers': '-1,-2,-3,-4', 'pooling_operation': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for lemma, pos in lemma_pos:\n",
    "    # [WARNING] if you run code for the first time uncomment line below, comment again after running this cell\n",
    "    #quotations = harvest_data_from_extended_senses(auth,f\"{lemma}_{pos}\")\n",
    "    quotations_path = f\"./data/sfrel_quotations_{lemma}_{pos}.pickle\"\n",
    "    vectorize_target_expressions(quotations_path,embedding_methods)"
   ]
  },
  {
   "source": [
    "# Evaluate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_cols = ['vector_bert_base_-1,-2,-3,-4_mean',\n",
    "                \"vector_blert_base_-1,-2,-3,-4_mean\",\n",
    "                'vector_bert_1850_-1,-2,-3,-4_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_sense(lemma,\n",
    "                pos,\n",
    "                senses,\n",
    "                relations=['seed','synonym'],\n",
    "                eval_mode='lemma_etal',\n",
    "                start=1760,\n",
    "                end=1920,\n",
    "                train_on_dev=True,\n",
    "                vector_cols=vector_cols):\n",
    "\n",
    "    df_train, df_val, df_test = binarize(lemma,\n",
    "                pos,\n",
    "                senses, \n",
    "                relations,\n",
    "                strict_filter=True,\n",
    "                start=start,\n",
    "                end=end,\n",
    "                eval_mode=eval_mode)\n",
    "\n",
    "    # no quotations for sense and timeframe\n",
    "    if df_train is None:\n",
    "        return None\n",
    "    \n",
    "    if train_on_dev:\n",
    "        df_train = pd.concat([df_train, df_val], axis=0)\n",
    "        df_train.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    df_train[\"nlp_full_text\"] = df_train.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "    df_val[\"nlp_full_text\"] = df_val.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "    df_test[\"nlp_full_text\"] = df_test.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "    # random\n",
    "    print(f'[LOG] computing baselines for {senses}')\n",
    "    df_test[\"random\"] = df_test.apply (lambda row: wsd.random_predict(), axis=1)\n",
    "\n",
    "    # retrieve and process definitions            \n",
    "    df_selected_senses = generate_definition_df(df_train,lemma,eval_mode=eval_mode)\n",
    "    df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n",
    "\n",
    "    # token overlap\n",
    "    df_test[\"def_tok_overlap_ranking\"] = df_test.apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "    # spacy sentence embeddings\n",
    "    df_test[\"sent_embedding\"] = df_test.apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "    #w2v lesk\n",
    "    # Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "    \n",
    "    df_test[\"w2v_lesk_ranking\"] = df_test.apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], df_selected_senses, wemb_model), axis=1)\n",
    "\n",
    "    #Bert lesk      \n",
    "    #df_test[\"bert_lesk_ranking\"] = df_test.apply (lambda row: wsd.bert_lesk_ranking(row[\"text\"][\"full_text\"], df_selected_senses, bert_sentsim_model), axis=1)\n",
    "\n",
    "\n",
    "    # supervised baselined (w-emb SVM) - careful this is a 19thC BL model\n",
    "    df_test[\"svm_wemb_baseline\"] = wsd.svm_wemb_baseline(df_train,df_test,wemb_model)\n",
    "\n",
    "    for vector_col in vector_cols:\n",
    "        print(f'[LOG] computing centoids for {senses} [BERT model = {vector_col}]' )\n",
    "        df_test[f\"bert_binary_centroid_{vector_col}\"] = df_test.apply(wsd.bert_binary_centroid_vector, \n",
    "                                        df_train = df_train, \n",
    "                                        vector_col=vector_col,\n",
    "                                        return_ranking=False, axis=1)\n",
    "\n",
    "        senseid2label = dict(df_test[['sense_id','label']].values)\n",
    "        df_test[f\"bert_centroid_sense_{vector_col}\"] = df_test.apply(wsd.bert_sense_centroid_vector,  \n",
    "                                                    senseid2label= senseid2label,\n",
    "                                                    vector_col=vector_col,\n",
    "                                                    df_train = df_train, axis=1)\n",
    "\n",
    "        centroid_vectors = df_train.groupby('label')[vector_col].apply(np.mean,axis=0)\n",
    "        sem_axis = centroid_vectors[1] - centroid_vectors[0] \n",
    "        df_test[f\"bert_contrast_{vector_col}\"] = df_test[vector_col].apply(wsd.bert_semaxis_vector,\n",
    "                                                    sem_axis=sem_axis,\n",
    "                                                    threshold=.0)\n",
    "\n",
    "        df_test[f\"bert_ts_binary_centroid_{vector_col}\"] = df_test.apply(wsd.bert_ts_binary_centroid_vector, \n",
    "                                                        df_train=df_train, \n",
    "                                                        ts_method='nearest',\n",
    "                                                        vector_col=vector_col,\n",
    "                                                        axis=1)\n",
    "\n",
    "        senseid2label = dict(df_test[['sense_id','label']].values)\n",
    "        df_test[f\"bert_ts_centroid_sense_{vector_col}\"] = df_test.apply(wsd.bert_ts_sense_centroid_vector,  \n",
    "                        senseid2label= senseid2label,\n",
    "                        ts_method='nearest',\n",
    "                        vector_col=vector_col,\n",
    "                        df_train = df_train, axis=1)\n",
    "\n",
    "        print(f'[LOG] traing classifier for {senses} [BERT model = {vector_col}]' )\n",
    "        X,y = list(df_train[vector_col].values), list(df_train.label.values)\n",
    "        #print('bert_clf_svm')\n",
    "        #svm_model = LinearSVC(random_state=0, C=.1, tol=1e-5,class_weight='balanced')\n",
    "        #svm_model.fit(X,y)\n",
    "        df_test[f\"bert_svm_{vector_col}\"] = \"0\"#wsd.clf_svm(vector_col,df_test, svm_model)\n",
    "\n",
    "        #print('bert_clf_perc')\n",
    "        perc_model = Perceptron(validation_fraction=.2, early_stopping=True,class_weight='balanced')\n",
    "        perc_model.fit(X,y)\n",
    "        df_test[f\"bert_perceptron_{vector_col}\"] = wsd.clf_perceptron(vector_col,df_test, perc_model)\n",
    "\n",
    "        #print('bert_clf_mlperc')\n",
    "        mlperc_model = MLPClassifier(validation_fraction=.2, early_stopping=True, solver='lbfgs',activation='relu')\n",
    "        mlperc_model.fit(X,y)\n",
    "        df_test[f\"bert_ml_perceptron_{vector_col}\"]  = wsd.clf_perceptron(vector_col,df_test, mlperc_model)\n",
    "\n",
    "\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test eval sense\n",
    "#eval_sense('machine','NN',{'machine_nn01-38476566'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we first define the serial version of the run\n",
    "# It combines both eval_sense and other parts to output the results\n",
    "\n",
    "def serial_run(lemma, pos, senses, eval_mode, relations, start=1760, end=1920, train_on_dev=True, vector_cols=vector_cols):\n",
    "    df_test = eval_sense(lemma,\n",
    "                         pos,\n",
    "                         senses,\n",
    "                         start=1760,\n",
    "                         end=1920,\n",
    "                         train_on_dev=True)\n",
    "\n",
    "    results_path = os.path.join('results', f\"{lemma}_{pos}\", eval_mode)\n",
    "    results_filename = '_'.join(senses) + \"~\" + \"+\".join(sorted(relations)) + \".csv\"\n",
    "    Path(results_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # IF df_test is None, create an empty DataFrame\n",
    "    if not isinstance(df_test, type(None)):\n",
    "        \n",
    "        baselines = ['id_x','label','random','def_tok_overlap_ranking', 'sent_embedding', 'w2v_lesk_ranking',                        'svm_wemb_baseline']\n",
    "        bert_methods = [[f\"bert_binary_centroid_{vector_col}\",f\"bert_centroid_sense_{vector_col}\",f\"bert_contrast_{vector_col}\",\n",
    "                        f\"bert_ts_binary_centroid_{vector_col}\",f\"bert_ts_centroid_sense_{vector_col}\"] \n",
    "                                    for vector_col in  vector_cols]\n",
    "        bert_methods = [i for tm in bert_methods for i in tm]\n",
    "\n",
    "        out_df = df_test.filter(baselines + bert_methods, axis=1)\n",
    "    else:\n",
    "        out_df = pd.DataFrame()\n",
    "\n",
    "    out_df.to_csv(os.path.join(results_path, results_filename), index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect a list of all runs, see list_jobs\n",
    "\n",
    "words = [['anger',\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],[\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],[\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],['woman','NN']]\n",
    "#words = [[\"anger\",\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],[\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],[\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],[\"technology\",\"NN\"],[\"woman\",\"NN\"]]\n",
    "\n",
    "words = [['machine','NN']]\n",
    "\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "\n",
    "wemb_model = Word2Vec.load(\"models/w2v_004/w2v_words.model\")\n",
    "\n",
    "# Download model from (warning: this is a contemporary model):\n",
    "# https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip\n",
    "\n",
    "#bert_sentsim_model = SentenceTransformer('models/bert/bert-base-nli-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list_jobs = []\n",
    "for lemma, pos in words:\n",
    "    quotations_path = f\"./data/sfrel_quotations_{lemma}_{pos}.pickle\"\n",
    "    lemma_senses = pd.read_pickle(f'./data/lemma_senses_{lemma}_{pos}.pickle')\n",
    "    \n",
    "    # this is the index of the lemma id <-- we could remove this later\n",
    "    idx = \"01\"\n",
    "    \n",
    "    senses = set(lemma_senses[lemma_senses.word_id==f'{lemma}_{pos.lower()}{idx}'].id)\n",
    "    \n",
    "    for sense in list(senses):\n",
    "        list_jobs.append([serial_run, (lemma, pos, {sense}, eval_mode, relations, 1760, 1920, True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[[<function __main__.serial_run(lemma, pos, senses, eval_mode, relations, start=1760, end=1920, train_on_dev=True, vector_cols=['vector_bert_base_-1,-2,-3,-4_mean', 'vector_blert_base_-1,-2,-3,-4_mean', 'vector_bert_1850_-1,-2,-3,-4_mean'])>,\n",
       "  ('machine',\n",
       "   'NN',\n",
       "   {'machine_nn01-38474820'},\n",
       "   'lemma_etal',\n",
       "   ['seed', 'synonym'],\n",
       "   1760,\n",
       "   1920,\n",
       "   True)],\n",
       " [<function __main__.serial_run(lemma, pos, senses, eval_mode, relations, start=1760, end=1920, train_on_dev=True, vector_cols=['vector_bert_base_-1,-2,-3,-4_mean', 'vector_blert_base_-1,-2,-3,-4_mean', 'vector_bert_1850_-1,-2,-3,-4_mean'])>,\n",
       "  ('machine',\n",
       "   'NN',\n",
       "   {'machine_nn01-38474140'},\n",
       "   'lemma_etal',\n",
       "   ['seed', 'synonym'],\n",
       "   1760,\n",
       "   1920,\n",
       "   True)]]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "list_jobs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "At this point, `list_jobs` contains a list of jobs to be run in parallel, e.g.: \n",
    "\n",
    "```python\n",
    "[   \n",
    "    [serial_run, (lemma1, pos1, ...)],\n",
    "    [serial_run, (lemma2, pos2, ...)],  \n",
    "    [serial_run, (...)],\n",
    "    ...\n",
    "] \n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[INFO] #requested processes: 8\n"
     ]
    }
   ],
   "source": [
    "# num_req_p: number of processes to be run in parallel\n",
    "myprocs = multiFunc(num_req_p=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#requested processed: 8\n#jobs: 26\n"
     ]
    }
   ],
   "source": [
    "# Add the list of jobs\n",
    "myprocs.add_list_jobs(list_jobs)\n",
    "print(myprocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " train = 128 val = 10 test = 23 quotations\n",
      "[LOG] 635 quotations selected\n",
      "[LOG] train = 489 val = 54 test = 92 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-20\n",
      "====================\n",
      "\u001b[92m2021-01-22 17:59:11\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 13\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:11\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:11\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 5\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 3 \n",
      "#Â of branches selected 0\n",
      "[LOG] 274 quotations selected\n",
      "[LOG] train = 207 val = 24 test = 43 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-21\n",
      "====================\n",
      "\u001b[92m2021-01-22 17:59:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 14\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 4\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 2 \n",
      "#Â of branches selected 0\n",
      "[LOG] 177 quotations selected\n",
      "[LOG] train = 133 val = 13 test = 31 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-22\n",
      "====================\n",
      "\u001b[92m2021-01-22 17:59:43\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 15\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:43\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 17:59:43\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 3\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 15 \n",
      "#Â of branches selected 0\n",
      "[LOG] 543 quotations selected\n",
      "[LOG] train = 432 val = 43 test = 68 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-23\n",
      "====================\n",
      "\u001b[92m2021-01-22 18:00:09\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 16\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:09\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:09\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 2\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 4 \n",
      "#Â of branches selected 0\n",
      "[LOG] 185 quotations selected\n",
      "[LOG] train = 142 val = 18 test = 25 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-24\n",
      "====================\n",
      "\u001b[92m2021-01-22 18:00:21\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 17\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:21\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:21\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 1\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 8 \n",
      "#Â of branches selected 0\n",
      "[LOG] 538 quotations selected\n",
      "[LOG] train = 428 val = 34 test = 76 quotations\n",
      "bert_centroid\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "[INFO] start job-25\n",
      "====================\n",
      "\u001b[92m2021-01-22 18:00:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 18\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 8\u001b[0m\n",
      "\u001b[92m2021-01-22 18:00:31\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 0\u001b[0m\n",
      "====================\n",
      "#Â senses before filtering by date = 517\n",
      "#Â senses after filtering by date = 352\n",
      "\n",
      "\n",
      "#Â of seed senses 22 \n",
      "#Â of synonyms 310 \n",
      "#Â of branch senses 0\n",
      "\n",
      "\n",
      "#Â of seeds selected 1 \n",
      "#Â of synonyms selected 6 \n",
      "#Â of branches selected 0\n",
      "[LOG] 585 quotations selected\n",
      "[LOG] train = 475 val = 51 test = 59 quotations\n",
      "baselines\n",
      "Using lemma_etal as evaluation mode.\n",
      "bert_centroid\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_centroid\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "bert_centroid\n",
      "bert_clf\n",
      "bert_clf_svm\n",
      "bert_clf_perc\n",
      "====================\n",
      "\u001b[92m2021-01-22 18:16:52\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#finished jobs: 26\u001b[0m\n",
      "\u001b[92m2021-01-22 18:16:52\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#running jobs: 0\u001b[0m\n",
      "\u001b[92m2021-01-22 18:16:52\u001b[0m \u001b[95mlwm-embeddings\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[92m#remained jobs: 0\u001b[0m\n",
      "====================\n",
      "Total time: 1171.0510337352753\n",
      "==========\n",
      "List of exceptions\n",
      "0 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "1 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "2 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "3 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "4 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "5 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "6 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "7 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "8 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "9 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "10 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "11 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "13 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "14 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "15 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "16 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "17 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "18 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "19 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "20 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "21 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "22 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "23 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "24 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "25 (NameError(\"name 'ys' is not defined\"), 'Traceback (most recent call last):\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/site-packages/parhugin/utils.py\", line 33, in run\\n    mp.Process.run(self)\\n  File \"/data/anaconda/envs/py37torch/lib/python3.7/multiprocessing/process.py\", line 99, in run\\n    self._target(*self._args, **self._kwargs)\\n  File \"<ipython-input-51-3d9894988eb0>\", line 10, in serial_run\\n    train_on_dev=True)\\n  File \"<ipython-input-49-2af5570852f8>\", line 99, in eval_sense\\n    perc_model.fit(X,ys)\\nNameError: name \\'ys\\' is not defined\\n')\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "myprocs.run_jobs(verbosity=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}