{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import defaultdict,Counter\n",
    "import statistics\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_lemmas(setting):\n",
    "    lemmas = []\n",
    "    if setting == \"all_lemmas\":\n",
    "        lemmas = [\"anger_NN\",\"apple_NN\",\"art_NN\", \"democracy_NN\",\n",
    "                  \"happiness_NN\", \"labour_NN\", \"machine_NN\", \"man_NN\",\n",
    "                  \"nation_NN\", \"power_NN\", \"slave_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"non_industrial\":\n",
    "        lemmas = [\"anger_NN\",\"apple_NN\",\"democracy_NN\",\n",
    "                  \"happiness_NN\",\"man_NN\",\n",
    "                  \"nation_NN\",\"slave_NN\",'woman_NN']\n",
    "\n",
    "    elif setting == \"industrial\":\n",
    "        lemmas = [\"art_NN\", \"labour_NN\", \"machine_NN\", \"power_NN\"]\n",
    "\n",
    "    elif setting == \"non_tech\":\n",
    "        lemmas = [\"anger_NN\",\"apple_NN\",\"art_NN\", \"democracy_NN\",\n",
    "                  \"happiness_NN\", \"labour_NN\", \"man_NN\",\n",
    "                  \"nation_NN\", \"slave_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"tech\":\n",
    "        lemmas = [\"machine_NN\", \"power_NN\"]\n",
    "\n",
    "    elif setting == \"human\":\n",
    "        lemmas = [\"slave_NN\", 'woman_NN', \"man_NN\"]\n",
    "\n",
    "    elif setting == \"emotion\":\n",
    "        lemmas = [\"happiness_NN\", \"anger_NN\"]\n",
    "\n",
    "    elif setting == \"abstract\":\n",
    "        lemmas = [\"happiness_NN\", \"anger_NN\", \"art_NN\", \"democracy_NN\",\n",
    "                  \"labour_NN\", \"nation_NN\"]\n",
    "\n",
    "    elif setting == \"abstract_wo_emotions\":\n",
    "        lemmas = [\"art_NN\", \"democracy_NN\",\n",
    "                  \"labour_NN\", \"nation_NN\"]\n",
    "\n",
    "    elif setting == \"concrete\":\n",
    "        lemmas = [\"apple_NN\", \"machine_NN\", \"man_NN\", \"slave_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"concrete_wo_machine\":\n",
    "        lemmas = [\"apple_NN\", \"man_NN\", \"slave_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"man_apple_woman\":\n",
    "        lemmas = [\"apple_NN\", \"man_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"apple\":\n",
    "        lemmas = [\"apple_NN\"]\n",
    "\n",
    "    elif setting == \"machine\":\n",
    "        lemmas = [\"machine_NN\"]\n",
    "\n",
    "    elif setting == \"slave\":\n",
    "        lemmas = [\"slave_NN\"]\n",
    "\n",
    "    elif setting == \"man_woman\":\n",
    "        lemmas = [\"man_NN\", \"woman_NN\"]\n",
    "        \n",
    "    if setting == \"all_wo_machine\":\n",
    "        lemmas = [\"anger_NN\",\"apple_NN\",\"art_NN\", \"democracy_NN\",\n",
    "                  \"happiness_NN\", \"labour_NN\", \"man_NN\",\n",
    "                  \"nation_NN\", \"power_NN\", \"slave_NN\", 'woman_NN']\n",
    "\n",
    "    elif setting == \"work_related\":\n",
    "        lemmas = [\"slave_NN\", \"machine_NN\", \"labour_NN\", \"power_NN\"]\n",
    "\n",
    "    elif setting == \"non_work_related\":\n",
    "        lemmas = [\"anger_NN\",\"apple_NN\",\"art_NN\", \"democracy_NN\",\n",
    "                  \"happiness_NN\", \"man_NN\",\n",
    "                  \"nation_NN\", 'woman_NN']\n",
    "        \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Optimal time range for a Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_daterange(results_path, lemmas, timestart, year_window, metric):\n",
    "    from sklearn.metrics import precision_recall_fscore_support\n",
    "    clf_dict = defaultdict(list)\n",
    "    results = {}\n",
    "    csv_files = results_path.glob(\"**/*.csv\")\n",
    "    for csv in csv_files:\n",
    "        current_csv = str(csv).split(\"/\")\n",
    "        current_lemma = current_csv[1]\n",
    "        current_sense = current_csv[3].split(\"~\")[0]\n",
    "        lemma_pickle = pd.read_pickle(\"data/lemma_senses_\" + current_lemma + \".pickle\")\n",
    "        sst = lemma_pickle[lemma_pickle[\"id\"] == current_sense].iloc[0][\"daterange.start\"]\n",
    "            \n",
    "        try:\n",
    "            df = pd.read_csv(csv)\n",
    "            \n",
    "            df = df[[\"label\",\"year\",\"quotation_id\",\"bert_centroid_sense_vector_bert_base_-1,-2,-3,-4_mean\",\n",
    "                     \"bert_centroid_sense_vector_bert_1850_-1,-2,-3,-4_mean\",\"bert_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean\"]]\n",
    "            df = df.rename(columns={\"bert_centroid_sense_vector_bert_base_-1,-2,-3,-4_mean\": \"bert_base_sense_centroid\",\n",
    "                                    \"bert_centroid_sense_vector_bert_1850_-1,-2,-3,-4_mean\": \"bert_1850_sense_centroid\",\n",
    "                                    \"bert_centroid_sense_vector_blert_base_-1,-2,-3,-4_mean\": \"bert_1900_sense_centroid\"})\n",
    "            df = df[df[\"year\"].between(timestart, timestart+(year_window*2))]\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "        \n",
    "        if current_lemma in lemmas:\n",
    "            for col in df.columns:\n",
    "                clf_dict[col].extend(df[col])\n",
    "\n",
    "    for colname, classifications in clf_dict.items():\n",
    "        if colname not in ('label','year','quotation_id') and colname.startswith(\"bert_\"):\n",
    "            p,r = [round(x,3) for x in precision_recall_fscore_support(clf_dict['label'],classifications,average='binary',pos_label=1)[:2] if x] \n",
    "            f1 = round((2*(p*r))/(p+r),3)\n",
    "            if metric == \"recall\":\n",
    "                results[colname] = round(r,3)\n",
    "            if metric == \"precision\":\n",
    "                results[colname] = round(p,3)\n",
    "            if metric == \"fscore\":\n",
    "                results[colname] = round(f1,3)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'PosixPath' and 'str'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fbc73b682404>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"BERTbase\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BERT1850\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BERT1900\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lower right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"plot_LM_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msetting\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_class1\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_50.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'PosixPath' and 'str'"
     ]
    }
   ],
   "source": [
    "setting = \"all_lemmas\"\n",
    "metric = \"fscore\"\n",
    "\n",
    "lemmas = select_lemmas(setting)\n",
    "\n",
    "path = Path('figures')\n",
    "path.mkdir(exist_ok=True)\n",
    "\n",
    "time_experiment = 2000 # Folder from which we select results\n",
    "test_daterange_start = 1760 # Quotations starting from\n",
    "year_window = 50\n",
    "bert_base = []\n",
    "bert_1850 = []\n",
    "bert_1900 = []\n",
    "time_mean = []\n",
    "for date_start in range(test_daterange_start, time_experiment - year_window,10):\n",
    "    results = find_optimal_daterange(Path('results_' + str(time_experiment)), lemmas, date_start, year_window, metric)\n",
    "    bert_base.append(results[\"bert_base_sense_centroid\"])\n",
    "    bert_1850.append(results[\"bert_1850_sense_centroid\"])\n",
    "    bert_1900.append(results[\"bert_1900_sense_centroid\"])\n",
    "    time_mean.append(date_start + year_window)\n",
    "    \n",
    "plt.plot(time_mean, bert_base)\n",
    "plt.plot(time_mean, bert_1850)\n",
    "plt.plot(time_mean, bert_1900)\n",
    "\n",
    "plt.legend([\"BERTbase\", \"BERT1850\", \"BERT1900\"], loc='lower right')\n",
    "\n",
    "plt.savefig(path / (\"plot_LM_\" + setting + \"_class1\" + metric + \"_50.png\"), dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration\n",
    "\n",
    "**[WARNING]** To run the following cell you will need to have generated the `lemma` and `quotation` dataframes for each headword.\n",
    "\n",
    "Code to generate table 1 describing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.classificaton_utils import binarize\n",
    "\n",
    "words = [['anger',\"NN\"],[\"apple\",\"NN\"],[\"art\",\"NN\"],[\"democracy\",\"NN\"],\n",
    "         [\"happiness\",\"NN\"],[\"labour\",\"NN\"],[\"machine\",\"NN\"],[\"man\",\"NN\"],\n",
    "         [\"nation\",\"NN\"],[\"power\",\"NN\"],[\"slave\",\"NN\"],['woman','NN']]\n",
    "\n",
    "experiment = {\"start\": 1760, \"end\": 1850, \"filter_val\": True, \"filter_test\": True}\n",
    "\n",
    "dr = dict()\n",
    "for lemma, pos in words:\n",
    "    print(\"### lemma: {} ###\".format(lemma))\n",
    "    quotations_path = f\"./data/sfrel_quotations_{lemma}_{pos}.pickle\"\n",
    "    lemma_senses = pd.read_pickle(f'./data/lemma_senses_{lemma}_{pos}.pickle')\n",
    "\n",
    "    senses = set(lemma_senses[lemma_senses.word_id.str.startswith(f'{lemma}_{pos.lower()}')][\"id\"])\n",
    "    relations = ['seed','synonym']\n",
    "    eval_mode = \"lemma_etal\"\n",
    "\n",
    "    df_train, df_val, df_test = binarize(lemma=lemma,\n",
    "                                    pos=pos,\n",
    "                                    senses=senses, \n",
    "                                    start=experiment[\"start\"],\n",
    "                                    end=experiment[\"end\"],\n",
    "                                    relations=relations,\n",
    "                                    eval_mode=eval_mode,\n",
    "                                    filter_val_by_year=experiment[\"filter_val\"],\n",
    "                                    filter_test_by_year=experiment[\"filter_test\"],\n",
    "                                    strict_filter=True)\n",
    "\n",
    "    df_all = pd.concat([df_train, df_val, df_test])\n",
    "    \n",
    "    unique_seed_senses = len(df_all[df_all[\"provenance_type\"] == \"seed\"][\"sense_id\"].unique())\n",
    "    unique_syn_senses = round(len(df_all[df_all[\"provenance_type\"] == \"synonym\"][\"sense_id\"].unique())/unique_seed_senses)\n",
    "    unique_other_senses = round(len(df_all[~df_all[\"provenance_type\"].isin([\"synonym\", \"seed\"])][\"sense_id\"].unique())/unique_seed_senses)\n",
    "    df_all_posq = df_all[df_all[\"label\"] == \"1\"]\n",
    "    df_all_negq = df_all[df_all[\"label\"] == \"0\"]\n",
    "    quotations_p = round(len(df_all_posq.quotation_id.unique())/unique_seed_senses)\n",
    "    quotations_n = round(len(df_all_negq.quotation_id.unique())/unique_seed_senses)\n",
    "    quotations = str(quotations_p) + \"/\" + str(quotations_n)\n",
    "    derived_senses = str(unique_syn_senses) + \"/\" + str(unique_other_senses)\n",
    "     \n",
    "    dr[lemma] = [unique_seed_senses, derived_senses, quotations]\n",
    "    \n",
    "data_description = pd.DataFrame.from_dict(dr, orient='index', columns=['Seeds','ExpSenses', 'Quotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_description.to_latex())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}