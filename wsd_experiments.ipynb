{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from pathlib import Path\n",
    "from utils import nlp_tools\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.classificaton_utils import binarize,generate_definition_df\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemma,pos = 'machine', \"NN\"\n",
    "senses = {'machine_nn01-38475923'}\n",
    "relations = ['seed','synonym'] # ,'descendant','sibling'\n",
    "\n",
    "# whether we use only information on the lemma for the predictive model (e.g. only the lemma senses definitions for lesk baselines)\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "\n",
    "df_train, df_val, df_test = binarize(lemma,\n",
    "                        pos,\n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=1910,\n",
    "                        eval_mode=eval_mode)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index(['sense_id', 'lemma_definition', 'definition', 'word_id', 'lemma',\n       'quotation_id', 'source', 'text', 'year'],\n      dtype='object')\n# senses before filtering by date = 517\n# senses after filtering by date = 356\n\n\n# of seed senses 23 \n# of synonyms 312 \n# of branch senses 0\n\n\n# of seeds selected 1 \n# of synonyms selected 8 \n# of branches selected 0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"nlp_full_text\"] = df_train.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_val[\"nlp_full_text\"] = df_val.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_test[\"nlp_full_text\"] = df_test.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using lemma_etal as evaluation mode.\n"
     ]
    }
   ],
   "source": [
    "df_selected_senses = generate_definition_df(df_train,lemma,eval_mode=eval_mode)\n",
    "\n",
    "df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n"
   ]
  },
  {
   "source": [
    "# Lesk-based Unsupervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa75de1797434f6590d4d84e203308ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.062, 0.333, 0.105], '0': [0.871, 0.474, 0.614]}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_test[\"random\"] = df_test.progress_apply (lambda row: wsd.random_predict(), axis=1)\n",
    "\n",
    "wsd.eval(\"random\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "57     0\n",
       "18     1\n",
       "92     0\n",
       "296    1\n",
       "257    0\n",
       "      ..\n",
       "295    1\n",
       "68     0\n",
       "265    1\n",
       "19     0\n",
       "280    0\n",
       "Name: random, Length: 63, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_test[\"random\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbaf995983eb481390cb95f6bdc9348e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.902, 0.965, 0.932]}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_test[\"def_tok_overlap_ranking\"] = df_test.progress_apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(\"def_tok_overlap_ranking\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "57     0\n",
       "18     0\n",
       "92     0\n",
       "296    0\n",
       "257    1\n",
       "      ..\n",
       "295    0\n",
       "68     0\n",
       "265    0\n",
       "19     0\n",
       "280    0\n",
       "Name: def_tok_overlap_ranking, Length: 63, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "df_test[\"def_tok_overlap_ranking\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [00:00<00:00, 345.73it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.905, 1.0, 0.95]}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_test[\"sent_embedding\"] = df_test.progress_apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(\"sent_embedding\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 17.03it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.903, 0.982, 0.941]}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "df_test[\"w2v_lesk_ranking\"] = df_test.progress_apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], df_selected_senses, wemb_model), axis=1)\n",
    "\n",
    "wsd.eval(\"w2v_lesk_ranking\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 63/63 [02:11<00:00,  2.09s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.25, 0.167, 0.2], '0': [0.915, 0.947, 0.931]}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Download model from (warning: this is a contemporary model):\n",
    "# https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip\n",
    "\n",
    "bert_sentsim_model = SentenceTransformer('models/bert/bert-base-nli-mean-tokens')\n",
    "df_test[\"bert_lesk_ranking\"] = df_test.progress_apply (lambda row: wsd.bert_lesk_ranking(row[\"text\"][\"full_text\"], df_selected_senses, bert_sentsim_model), axis=1)\n",
    "\n",
    "wsd.eval(\"bert_lesk_ranking\",df_test)"
   ]
  },
  {
   "source": [
    "# Supervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.903, 0.982, 0.941]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "df_test[\"svm_wemb_baseline\"] = wsd.svm_wemb_baseline(df_train,df_test,wemb_model)\n",
    "\n",
    "wsd.eval(\"svm_wemb_baseline\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results/'+ lemma+\"_\"+pos +\"/\"+ eval_mode+\"/\"\n",
    "results_filename = \"+\".join(sorted(senses)) +\"~\"+ \"+\".join(sorted(relations))+\".csv\"\n",
    "Path(results_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_df = df_test.filter(['id_x','label','random','def_tok_overlap_ranking', 'sent_embedding', 'w2v_lesk_ranking',\n",
    "       'bert_lesk_ranking', 'svm_wemb_baseline'], axis=1)\n",
    "\n",
    "out_df.to_csv(results_path+results_filename, index=False)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}