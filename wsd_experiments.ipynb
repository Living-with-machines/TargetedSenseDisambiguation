{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from utils import nlp_tools\n",
    "from utils.classificaton_utils import binarize,generate_definition_df\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemma_id = 'machine_nn01'\n",
    "senses = {'machine_nn01-38475835','machine_nn01-38475923'}\n",
    "relations = ['seed','synonym','descendant','sibling']\n",
    "\n",
    "# whether we use only information on the lemma for the predictive model (e.g. only the lemma senses definitions for lesk baselines)\n",
    "eval_mode = \"lemma\" # or lemma_etal\n",
    "\n",
    "df_train, df_val, df_test = binarize(lemma_id, \n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=1910)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# senses before filtering by date = 8383\n",
      "# senses after filtering by date = 5904\n",
      "\n",
      "\n",
      "# of seed senses 23 \n",
      "# of synonyms 312 \n",
      "# of branch senses 4968\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 8 \n",
      "# of branches selected 5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"nlp_full_text\"] = df_train.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_val[\"nlp_full_text\"] = df_val.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_test[\"nlp_full_text\"] = df_test.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_senses = generate_definition_df(df_train,lemma_id,eval_mode=\"lemma\")\n",
    "\n",
    "df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n"
   ]
  },
  {
   "source": [
    "# Lesk-based Unsupervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 745.53it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, 0.81)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "approach = \"random\"\n",
    "\n",
    "df_test[approach] = df_test.progress_apply (lambda row: wsd.random_predict(df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 471.85it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.0, 0.077, 0.143, 0.857)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# be careful: i am using the example sentence (row[\"text\"][\"full_text\"]) as the input sentence and then measure its word overlap with the definition (see function). if you instead want to use the example as training data, we need to split in train/test\n",
    "\n",
    "approach = \"def_tok_overlap_ranking\"\n",
    "\n",
    "df_test[approach] = df_test.progress_apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 474.30it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, 0.845)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "approach = \"sent_embedding\"\n",
    "\n",
    "df_test[approach] = df_test.progress_apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:04<00:00, 17.96it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0, 0.821)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "approach = \"w2v_lesk_ranking\"\n",
    "\n",
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "df_test[approach] = df_test.progress_apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], df_selected_senses, wemb_model), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [05:54<00:00,  4.22s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.25, 0.154, 0.19, 0.798)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "approach = \"bert_lesk_ranking\"\n",
    "\n",
    "# Download model from (warning: this is a contemporary model):\n",
    "# https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip\n",
    "bert_sentsim_model = SentenceTransformer('models/bert/bert-base-nli-mean-tokens')\n",
    "df_test[approach] = df_test.progress_apply (lambda row: wsd.bert_lesk_ranking(row[\"text\"][\"full_text\"], df_selected_senses, bert_sentsim_model), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  },
  {
   "source": [
    "# Supervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:41<00:00,  2.00it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.155, 1.0, 0.268, 0.155)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "approach = \"svm_wemb_baseline\"\n",
    "\n",
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "df_test[approach] = df_test.progress_apply(lambda row: wsd.svm_wemb_baseline(df_train,df_test,wemb_model), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py37deezy",
   "display_name": "Python (py37deezy)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}