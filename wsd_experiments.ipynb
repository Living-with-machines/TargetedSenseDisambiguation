{
 "cells": [
  {
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from utils import nlp_tools\n",
    "from utils.classificaton_utils import binarize\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemma_id = 'machine_nn01'\n",
    "senses = {'machine_nn01-38475835','machine_nn01-38475923'}\n",
    "relations = ['seed','synonym','descendant','sibling']\n",
    "\n",
    "df_source = pd.read_pickle(f'./data/extended_{lemma_id}.pickle')\n",
    "\n",
    "df_quotations = binarize(lemma_id, \n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=1910)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_selected_senses = set(df_quotations[\"sense_id\"])\n",
    "all_labels = df_quotations[['sense_id','label']]\n",
    "all_labels = all_labels.rename(columns={'sense_id': 'id'})\n",
    "all_labels.drop_duplicates(inplace = True)\n",
    "all_labels = all_labels.reset_index(drop=True)\n",
    "\n",
    "df_selected_senses = df_source[df_source.id.isin(all_selected_senses)]\n",
    "df_selected_senses = df_selected_senses[['lemma','id','definition']]\n",
    "df_selected_senses.drop_duplicates(inplace = True)\n",
    "df_selected_senses = df_selected_senses[df_selected_senses['definition'].notna()]\n",
    "df_selected_senses = df_selected_senses.reset_index(drop=True)\n",
    "\n",
    "df_selected_senses = pd.merge(all_labels, df_selected_senses, on='id')\n",
    "\n",
    "df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n",
    "\n",
    "df_selected_senses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quotations[\"nlp_full_text\"] = df_quotations.apply (lambda row: nlp_tools.preprocess(row[\"text\"][\"full_text\"]), axis=1)\n",
    "df_quotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "approach = \"random\"\n",
    "\n",
    "df_quotations[approach] = df_quotations.progress_apply (lambda row: wsd.random_predict(df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# be careful: i am using the example sentence (row[\"text\"][\"full_text\"]) as the input sentence and then measure its word overlap with the definition (see function). if you instead want to use the example as training data, we need to split in train/test\n",
    "\n",
    "approach = \"def_tok_overlap_ranking\"\n",
    "\n",
    "df_quotations[approach] = df_quotations.progress_apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"sent_embedding\"\n",
    "\n",
    "df_quotations[approach] = df_quotations.progress_apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(approach,df_quotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"w2v_lesk_ranking\"\n",
    "\n",
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "machine_df[approach] = machine_df.progress_apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], definition_df, wemb_model), axis=1)\n",
    "\n",
    "wsd.eval(machine_df[approach],machine_df[\"sense_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach = \"bert_lesk_ranking\"\n",
    "\n",
    "# Download model from (warning: this is a contemporary model):\n",
    "# https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip\n",
    "bert_sentsim_model = SentenceTransformer('models/bert/bert-base-nli-mean-tokens')\n",
    "machine_df[approach] = machine_df.progress_apply (lambda row: wsd.bert_lesk_ranking(row[\"text\"][\"full_text\"], definition_df, bert_sentsim_model), axis=1)\n",
    "\n",
    "wsd.eval(machine_df[approach],machine_df[\"sense_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37torch",
   "language": "python",
   "name": "py37torch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}