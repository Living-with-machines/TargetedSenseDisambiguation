{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from tasks import wsd\n",
    "from pathlib import Path\n",
    "from utils import nlp_tools\n",
    "from tqdm.auto import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from utils.classificaton_utils import binarize,generate_definition_df\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "lemma_id = 'machine_nn01'\n",
    "senses = {'machine_nn01-38475923'}\n",
    "relations = ['seed','synonym','descendant','sibling']\n",
    "\n",
    "# whether we use only information on the lemma for the predictive model (e.g. only the lemma senses definitions for lesk baselines)\n",
    "eval_mode = \"lemma_etal\" # lemma or lemma_etal\n",
    "\n",
    "df_train, df_val, df_test = binarize(lemma_id, \n",
    "                        senses, \n",
    "                        relations,\n",
    "                        strict_filter=True,\n",
    "                        start=1700,\n",
    "                        end=1910,\n",
    "                        eval_mode=eval_mode)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# senses before filtering by date = 8383\n",
      "# senses after filtering by date = 5904\n",
      "\n",
      "\n",
      "# of seed senses 23 \n",
      "# of synonyms 312 \n",
      "# of branch senses 4968\n",
      "\n",
      "\n",
      "# of seeds selected 1 \n",
      "# of synonyms selected 8 \n",
      "# of branches selected 5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"nlp_full_text\"] = df_train.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_val[\"nlp_full_text\"] = df_val.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)\n",
    "\n",
    "df_test[\"nlp_full_text\"] = df_test.apply (lambda row: nlp_tools.preprocess(row[\"full_text\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "We are not offering this functionality yet, defaulting to 'lemma' !!\n"
     ]
    }
   ],
   "source": [
    "df_selected_senses = generate_definition_df(df_train,lemma_id,eval_mode=eval_mode)\n",
    "\n",
    "df_selected_senses[\"nlp_definition\"] = df_selected_senses.apply (lambda row: nlp_tools.preprocess(row[\"definition\"]), axis=1)\n"
   ]
  },
  {
   "source": [
    "# Lesk-based Unsupervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 37617.08it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.154, 0.462, 0.231], '0': [0.844, 0.535, 0.655]}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_test[\"random\"] = df_test.progress_apply (lambda row: wsd.random_predict(), axis=1)\n",
    "\n",
    "wsd.eval(\"random\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 458.34it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [1.0, 0.077, 0.143], '0': [0.855, 1.0, 0.922]}"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "df_test[\"def_tok_overlap_ranking\"] = df_test.progress_apply (lambda row: wsd.tok_overlap_ranking(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(\"def_tok_overlap_ranking\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 485.52it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.845, 1.0, 0.916]}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "df_test[\"sent_embedding\"] = df_test.progress_apply (lambda row: wsd.sent_embedding(row[\"nlp_full_text\"], df_selected_senses), axis=1)\n",
    "\n",
    "wsd.eval(\"sent_embedding\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [00:04<00:00, 17.50it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.0, 0.0, 0.0], '0': [0.841, 0.972, 0.902]}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "df_test[\"w2v_lesk_ranking\"] = df_test.progress_apply (lambda row: wsd.w2v_lesk_ranking(row[\"nlp_full_text\"], df_selected_senses, wemb_model), axis=1)\n",
    "\n",
    "wsd.eval(\"w2v_lesk_ranking\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 84/84 [02:37<00:00,  1.88s/it]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.25, 0.154, 0.19], '0': [0.855, 0.915, 0.884]}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Download model from (warning: this is a contemporary model):\n",
    "# https://public.ukp.informatik.tu-darmstadt.de/reimers/sentence-transformers/v0.2/bert-base-nli-mean-tokens.zip\n",
    "\n",
    "bert_sentsim_model = SentenceTransformer('models/bert/bert-base-nli-mean-tokens')\n",
    "df_test[\"bert_lesk_ranking\"] = df_test.progress_apply (lambda row: wsd.bert_lesk_ranking(row[\"text\"][\"full_text\"], df_selected_senses, bert_sentsim_model), axis=1)\n",
    "\n",
    "wsd.eval(\"bert_lesk_ranking\",df_test)"
   ]
  },
  {
   "source": [
    "# Supervised Approaches"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'1': [0.714, 0.385, 0.5], '0': [0.896, 0.972, 0.932]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Warning: I use a Word2vec model trained on all 19thC BL corpus that is locally stored.\n",
    "wemb_model = Word2Vec.load(\"models/w2v/w2v_v004/w2v_words.model\")\n",
    "\n",
    "df_test[\"svm_wemb_baseline\"] = wsd.svm_wemb_baseline(df_train,df_test,wemb_model)\n",
    "\n",
    "wsd.eval(\"svm_wemb_baseline\",df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = 'results/'+ lemma_id +\"/\"+ eval_mode+\"/\"\n",
    "results_filename = \"+\".join(senses) +\"~\"+ \"+\".join(relations)+\".csv\"\n",
    "Path(results_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_df = df_test.filter(['id_x','label','random','def_tok_overlap_ranking', 'sent_embedding', 'w2v_lesk_ranking',\n",
    "       'bert_lesk_ranking', 'svm_wemb_baseline'], axis=1)\n",
    "\n",
    "out_df.to_csv(results_path+results_filename, index=False)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "py37torch",
   "display_name": "py37torch",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}