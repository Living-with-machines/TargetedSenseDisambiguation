# HistoricalDictionaryExpansion

Table of contents
-----------------
- [Installation and setup](#installation)
- [Running the code](#code)

## Installation

We strongly recommend installation via Anaconda:

* Refer to [Anaconda website and follow the instructions](https://docs.anaconda.com/anaconda/install/).

* Create a new environment:

```bash
conda create -n py37_hde python=3.7
```

* Activate the environment:

```bash
conda activate py37_hde
```

* Clone source code:

```bash
git clone https://github.com/Living-with-machines/HistoricalDictionaryExpansion.git
```

* Install dependencies:

```bash
cd /path/to/my/HistoricalDictionaryExpansion
pip install -r requirements.txt
```

Also, we use a [spaCy](https://spacy.io/) model: [en_core_web_lg](https://spacy.io/models/en#en_core_web_lg) which can be installed:

```bash
python -m spacy download en_core_web_lg
```

## Code

This section explain how to run the code. For most of scripts you'd need credentials for the Oxford Historical Dictionary Research API. These scripts are marked by `\*\*`. More information on obtaining access to the API can be found [here](https://languages.oup.com/research/oed-researcher-api/)

### Generate Dataframe

This script downloads data from the API for a given headword and vectorizes the keyword of the quotations.

**[WARNING]** This script also requires access to the historical BERT models which are not provided at the moment. Models will be released upon publication.

```python
python generate_dataframes.py --lemma='democracy' --pos='NN'
```

All results should be saved in the `/data` folder. Almost all next steps require these data as input.

### Running Experiments

#### Comparing BERT models

The code snippet below runs the main experiment that tests the effect of plugging in historical BERT models.

```python
python run_experiment.py "1"
python run_experiment.py "2"
python run_experiment.py "3"
```


All results should be saved in `result_{year}` folder.

####Â Time-sensitive approaches

To create results files for the time-sensitive methods, run:

```python
python python run_experiment_ts_disambiguation.py
```

Then open `run_experiment_ts_disambiguation.py`, changes lines 150 and 151 from:

```python
END = 1850 
RESULTS_PATH_BASE = "results_ts_1850"
```

to:

```python
END = 1920 
RESULTS_PATH_BASE = "results_ts_1920"
```

Save changes and run again:

```python
python python run_experiment_ts_disambiguation.py
```

#### Case-studies

To run the case studies, execute:

```python
python run_experiment_curated_cases.py 
```

Then changes lines 147-148 from:

```python
RELATIONS = ['seed'] 
EVAL_MODE = 'lemma' 
```

to:

```python
RELATIONS = ['seed','synonym'] 
EVAL_MODE = 'lemma_etal' 
```

And change line 167 from:

```python
RESULTS_PATH_BASE = 'results_curated_1920_seed'
```

to:

```python
RESULTS_PATH_BASE = 'results_curated_1920_syn'
```

### Create Results

To create the results from the output generated by the experiments, run the cells in `create_results_tables.ipynb`. This notebooks is runnable using the `.csv` files with results provided by this `.zip` archive.

### Explore Results

To explore results and recreate Figure 1, run cells in `explore_results.ipynb`. This notebooks requires output from `generate_dataframes.py` (saved in the `./data` folder).

## Fin.