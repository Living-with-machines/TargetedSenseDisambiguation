{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1-dataframe\u001b[m\r\n",
      "  19-machine-tagger\u001b[m\r\n",
      "  3-group-senses\u001b[m\r\n",
      "  4-semantic-provenance\u001b[m\r\n",
      "* \u001b[32m44-kNN-BERT-baseline\u001b[m\r\n",
      "  dev\u001b[m\r\n",
      "  master\u001b[m\r\n",
      "  oed-experiments\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!git branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import flair\n",
    "from flair.data import Sentence\n",
    "from utils.classificaton_utils import *\n",
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_type = TransformerWordEmbeddings('bert-base-uncased',\n",
    "                                           layers='-1,-2,-3,-4',\n",
    "                                           pooling_operation='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>lemma</th>\n",
       "      <th>source</th>\n",
       "      <th>oed_url</th>\n",
       "      <th>word_id</th>\n",
       "      <th>sense_id</th>\n",
       "      <th>datestring</th>\n",
       "      <th>first_in_word</th>\n",
       "      <th>oed_reference</th>\n",
       "      <th>first_in_sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pigmeat_nn01-13163366</td>\n",
       "      <td>{'keyword': 'pig-meat', 'full_text': 'I was at...</td>\n",
       "      <td>1754</td>\n",
       "      <td>pigmeat</td>\n",
       "      <td>{'title': 'Connoisseur', 'author': 'G. Colman'...</td>\n",
       "      <td>https://www.oed.com/view/Entry/237320#eid13163366</td>\n",
       "      <td>pigmeat_nn01</td>\n",
       "      <td>pigmeat_nn01-13163363</td>\n",
       "      <td>1754</td>\n",
       "      <td>True</td>\n",
       "      <td>pigmeat, n., sense 1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pigmeat_nn01-13163379</td>\n",
       "      <td>{'keyword': 'pig-meat', 'full_text': 'In short...</td>\n",
       "      <td>1784</td>\n",
       "      <td>pigmeat</td>\n",
       "      <td>{'title': 'Year's Journey through Paix Bâs', '...</td>\n",
       "      <td>https://www.oed.com/view/Entry/237320#eid13163379</td>\n",
       "      <td>pigmeat_nn01</td>\n",
       "      <td>pigmeat_nn01-13163363</td>\n",
       "      <td>1784</td>\n",
       "      <td>False</td>\n",
       "      <td>pigmeat, n., sense 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>pigmeat_nn01-13163399</td>\n",
       "      <td>{'keyword': 'pig meat', 'full_text': 'It preve...</td>\n",
       "      <td>1817</td>\n",
       "      <td>pigmeat</td>\n",
       "      <td>{'title': 'Parl. Deb.', 'author': None, 'gende...</td>\n",
       "      <td>https://www.oed.com/view/Entry/237320#eid13163399</td>\n",
       "      <td>pigmeat_nn01</td>\n",
       "      <td>pigmeat_nn01-13163363</td>\n",
       "      <td>1817</td>\n",
       "      <td>False</td>\n",
       "      <td>pigmeat, n., sense 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>pigmeat_nn01-13163416</td>\n",
       "      <td>{'keyword': 'pig meat', 'full_text': 'In most ...</td>\n",
       "      <td>1897</td>\n",
       "      <td>pigmeat</td>\n",
       "      <td>{'title': 'Syst. Med.', 'author': 'T. C. Allbu...</td>\n",
       "      <td>https://www.oed.com/view/Entry/237320#eid13163416</td>\n",
       "      <td>pigmeat_nn01</td>\n",
       "      <td>pigmeat_nn01-13163363</td>\n",
       "      <td>1897</td>\n",
       "      <td>False</td>\n",
       "      <td>pigmeat, n., sense 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pigmeat_nn01-13163425</td>\n",
       "      <td>{'keyword': 'pig meat', 'full_text': 'Beef tak...</td>\n",
       "      <td>1918</td>\n",
       "      <td>pigmeat</td>\n",
       "      <td>{'title': 'Times', 'author': None, 'gender': N...</td>\n",
       "      <td>https://www.oed.com/view/Entry/237320#eid13163425</td>\n",
       "      <td>pigmeat_nn01</td>\n",
       "      <td>pigmeat_nn01-13163363</td>\n",
       "      <td>1918</td>\n",
       "      <td>False</td>\n",
       "      <td>pigmeat, n., sense 1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                               text  \\\n",
       "0  pigmeat_nn01-13163366  {'keyword': 'pig-meat', 'full_text': 'I was at...   \n",
       "1  pigmeat_nn01-13163379  {'keyword': 'pig-meat', 'full_text': 'In short...   \n",
       "2  pigmeat_nn01-13163399  {'keyword': 'pig meat', 'full_text': 'It preve...   \n",
       "3  pigmeat_nn01-13163416  {'keyword': 'pig meat', 'full_text': 'In most ...   \n",
       "4  pigmeat_nn01-13163425  {'keyword': 'pig meat', 'full_text': 'Beef tak...   \n",
       "\n",
       "   year    lemma                                             source  \\\n",
       "0  1754  pigmeat  {'title': 'Connoisseur', 'author': 'G. Colman'...   \n",
       "1  1784  pigmeat  {'title': 'Year's Journey through Paix Bâs', '...   \n",
       "2  1817  pigmeat  {'title': 'Parl. Deb.', 'author': None, 'gende...   \n",
       "3  1897  pigmeat  {'title': 'Syst. Med.', 'author': 'T. C. Allbu...   \n",
       "4  1918  pigmeat  {'title': 'Times', 'author': None, 'gender': N...   \n",
       "\n",
       "                                             oed_url       word_id  \\\n",
       "0  https://www.oed.com/view/Entry/237320#eid13163366  pigmeat_nn01   \n",
       "1  https://www.oed.com/view/Entry/237320#eid13163379  pigmeat_nn01   \n",
       "2  https://www.oed.com/view/Entry/237320#eid13163399  pigmeat_nn01   \n",
       "3  https://www.oed.com/view/Entry/237320#eid13163416  pigmeat_nn01   \n",
       "4  https://www.oed.com/view/Entry/237320#eid13163425  pigmeat_nn01   \n",
       "\n",
       "                sense_id datestring  first_in_word         oed_reference  \\\n",
       "0  pigmeat_nn01-13163363       1754           True  pigmeat, n., sense 1   \n",
       "1  pigmeat_nn01-13163363       1784          False  pigmeat, n., sense 1   \n",
       "2  pigmeat_nn01-13163363       1817          False  pigmeat, n., sense 1   \n",
       "3  pigmeat_nn01-13163363       1897          False  pigmeat, n., sense 1   \n",
       "4  pigmeat_nn01-13163363       1918          False  pigmeat, n., sense 1   \n",
       "\n",
       "   first_in_sense  \n",
       "0            True  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotations_df = pd.read_pickle('./data/quotations_all_machine_nn01.pickle')\n",
    "quotations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69843, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_quotations = filter_quotations_by_year(quotations_df,1760,1920)\n",
    "selected_quotations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_quotations.apply(get_target_token_vector,\n",
    "#                                     embedding_type=embedding_type,\n",
    "#                                     axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_quotations_by_year(\n",
    "                      df_quotations:  pd.DataFrame,\n",
    "                      start:int,\n",
    "                      end: int\n",
    "                    ) -> pd.DataFrame:\n",
    "    \"\"\"Create a dataframe with quotations and their metadata for \n",
    "    for a specific year range\n",
    "    \n",
    "    Arguments:\n",
    "        df_quotations: dataframe with quotations, created using harvest_quotations_by_sense_id\n",
    "        start (int): start year\n",
    "        end (int):end year\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame with quotations\n",
    "        \n",
    "    \"\"\"\n",
    "    df = pd.concat([\n",
    "        pd.DataFrame.from_records(df_quotations.text.values),\n",
    "        pd.DataFrame.from_records(df_quotations.source.values)\n",
    "            ], axis=1)\n",
    "    df['year'] = df_quotations['year']\n",
    "    df['sense_id'] = df_quotations['sense_id']\n",
    "    df['word_id'] = df_quotations['word_id']\n",
    "    #df = df[df.sense_id.isin(senses)]\n",
    "    df = df[(start <= df.year) & (df.year <= end)]\n",
    "    \n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_target_token_vector(row: pd.Series, \n",
    "                            embedding_type: TransformerWordEmbeddings,\n",
    "                            punctuation: str = '!\"#—$%&\\()*+,./:;\\'\\—-<=>?@[\\\\]^_`{|}~‘’'):\n",
    "    \"\"\"\n",
    "    Get a vector representation for a target expression in context.\n",
    "    If the target expression consists of multiple words we average the \n",
    "    multiple vector representations.\n",
    "    \n",
    "    Arguments:\n",
    "        row (pd.Series): a row from a quotations dataframe created by \n",
    "                        the function filter_quotations_by_year\n",
    "    Returns:\n",
    "        a np.array that captures the last layer(s) of the transformer\n",
    "    \"\"\"\n",
    "    # replace all punctuation with white spaces\n",
    "    text = ''.join([' ' if c in punctuation else c  for c in row.full_text.lower()])\n",
    "    \n",
    "    # if there is no quotation return None\n",
    "    if text is '':\n",
    "        return None\n",
    "    \n",
    "    text = Sentence(text,use_tokenizer=False)\n",
    "    target = row.keyword # the offset as recorded by the OED\n",
    "    vectors = []; quotation_target_tokens = [] # we collect the target tokens collected in the quotation\n",
    "                                               # and match those with the target expression as a check (see below)\n",
    "    \n",
    "    # if there is no target word return none\n",
    "    # remove punctuation from target expression\n",
    "    if target is not None:\n",
    "        target = ''.join([' ' if c in punctuation else c  for c in target.lower()])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # get offsets of the target expression in the quotations\n",
    "    start_position = row.keyword_offset\n",
    "    end_position = start_position + len(target)\n",
    "    \n",
    "    # embedd text\n",
    "    embedding_type.embed(text)\n",
    "    \n",
    "    for token in text:\n",
    "        # here we rely on the FLAIR offset annotation in combination with tokenisation\n",
    "        # double check if this works properly\n",
    "        if (token.start_pos >= start_position) and (token.start_pos < end_position):\n",
    "            vectors.append(token.embedding.numpy())\n",
    "            quotation_target_tokens.append(token.text)\n",
    "    if vectors:\n",
    "        if ' '.join(quotation_target_tokens) != ' '.join(target.split()):\n",
    "            print('Warning: could not properly match',' '.join(target.split()), ' with ',' '.join(quotation_target_tokens))\n",
    "        \n",
    "        return np.mean(vectors, axis=0)\n",
    "    \n",
    "    return None\n",
    "def get_target_token_vector(row: pd.Series, \n",
    "                            embedding_type: TransformerWordEmbeddings,\n",
    "                            punctuation: str = '!\"#—$%&\\()*+,./:;\\'\\—-<=>?@[\\\\]^_`{|}~‘’'):\n",
    "    \"\"\"\n",
    "    Get a vector representation for a target expression in context.\n",
    "    If the target expression consists of multiple words we average the \n",
    "    multiple vector representations.\n",
    "    \n",
    "    Arguments:\n",
    "        row (pd.Series): a row from a quotations dataframe created by \n",
    "                        the function filter_quotations_by_year\n",
    "    Returns:\n",
    "        a np.array that captures the last layer(s) of the transformer\n",
    "    \"\"\"\n",
    "    # replace all punctuation with white spaces\n",
    "    text = ''.join([' ' if c in punctuation else c  for c in row.full_text.lower()])\n",
    "    \n",
    "    # if there is no quotation return None\n",
    "    if text is '':\n",
    "        return None\n",
    "    \n",
    "    text = Sentence(text,use_tokenizer=False)\n",
    "    target = row.keyword # the offset as recorded by the OED\n",
    "    vectors = []; quotation_target_tokens = [] # we collect the target tokens collected in the quotation\n",
    "                                               # and match those with the target expression as a check (see below)\n",
    "    \n",
    "    # if there is no target word return none\n",
    "    # remove punctuation from target expression\n",
    "    if target is not None:\n",
    "        target = ''.join([' ' if c in punctuation else c  for c in target.lower()])\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "    # get offsets of the target expression in the quotations\n",
    "    start_position = row.keyword_offset\n",
    "    end_position = start_position + len(target)\n",
    "    \n",
    "    # embedd text\n",
    "    embedding_type.embed(text)\n",
    "    \n",
    "    for token in text:\n",
    "        # here we rely on the FLAIR offset annotation in combination with tokenisation\n",
    "        # double check if this works properly\n",
    "        if (token.start_pos >= start_position) and (token.start_pos < end_position):\n",
    "            vectors.append(token.embedding.numpy())\n",
    "            quotation_target_tokens.append(token.text)\n",
    "    if vectors:\n",
    "        if ' '.join(quotation_target_tokens) != ' '.join(target.split()):\n",
    "            print('Warning: could not properly match',' '.join(target.split()), ' with ',' '.join(quotation_target_tokens))\n",
    "        \n",
    "        return np.mean(vectors, axis=0)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# X = [v.reshape(-1) for v in quot_sel.vector if v is not None]\n",
    "# senses = [color_codes[s] for s,v in zip(quot_sel.sense_id,quot_sel.vector) if v is not None]\n",
    "# #\n",
    "\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "# fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "# tsne = TSNE(n_components=2, random_state=0,metric='cosine')\n",
    "# X_2d = tsne.fit_transform(X)\n",
    "\n",
    "# for i,x in enumerate(X):\n",
    "\n",
    "#     plt.scatter(X_2d[i, 0], X_2d[i, 1],c=senses[i]) \n",
    "    \n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
