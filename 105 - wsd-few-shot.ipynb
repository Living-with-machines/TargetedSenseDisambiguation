{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.classificaton_utils import binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flair.models.text_classification_model import TARSClassifier\n",
    "from flair.datasets import SentenceDataset\n",
    "from flair.data import Sentence, Corpus\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "flair.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma, pos = 'machine','NN'\n",
    "senses = {'machine_nn01-38475835','machine_nn01-38475923'}\n",
    "relations = ['seed','synonym'] #Â 'descendant','sibling'\n",
    "\n",
    "train, val, test  = binarize(lemma,\n",
    "                            pos, \n",
    "                            senses, \n",
    "                            relations,\n",
    "                            strict_filter=True,\n",
    "                            start=1700,\n",
    "                            end=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape,test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enclose_keyword(row:pd.Series,\n",
    "                    enclose_token:str='$') -> str:\n",
    "    \"\"\"enclose keyword with specific token to point\n",
    "    learner towards to word it has to focus on. this\n",
    "    is part of the weak supervision when learning\n",
    "    from context/quotations.\n",
    "    Arguments:\n",
    "        row (pd.Series): row of quotations dataframe\n",
    "        enclose_token (str): use token to mark target expression\n",
    "                    effectively this serves begin and end token\n",
    "    Returns:\n",
    "        quotation with target token marked by `enclose_token`\n",
    "    \"\"\"\n",
    "    sentence = ''\n",
    "    for i,c in enumerate(row.full_text):\n",
    "        if i == int(row.keyword_offset):\n",
    "            sentence+=enclose_token + ' '\n",
    "        elif i ==int(row.keyword_offset + len(row.keyword)):\n",
    "            sentence+= ' ' + enclose_token\n",
    "        sentence+=c\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [(enclose_keyword(row),\n",
    "                    row.text.get('keyword',''),\n",
    "                    row.label)\n",
    "                        for i,row in train.iterrows()]\n",
    "\n",
    "# Add definitions to train set:\n",
    "train_sentences += [(row.keyword + \": \" + row.definition,\n",
    "                    row.keyword,\n",
    "                    row.label)\n",
    "                        for i,row in train[[\"definition\", \"label\", \"keyword\"]].drop_duplicates(subset=[\"definition\", \"label\"]).iterrows()]\n",
    "                \n",
    "train_sentences = [Sentence(s + ' ' + t).add_label('machine_or_not',l) for s,t,l in train_sentences if s and t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [(enclose_keyword(row),\n",
    "                    row.text.get('keyword',''),\n",
    "                    row.label)\n",
    "                        for i,row in test.iterrows()]\n",
    "                \n",
    "test_sentences = [Sentence(s + ' ' + t).add_label('machine_or_not',l) for s,t,l in test_sentences if s and t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = SentenceDataset(train_sentences)\n",
    "testset = SentenceDataset(test_sentences)\n",
    "corpus = Corpus(train=trainset, test=testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 1. load base TARS\n",
    "tars = TARSClassifier.load('tars-base')\n",
    "\n",
    "# 2. make the model aware of the desired set of labels from the new corpus\n",
    "tars.add_and_switch_to_new_task(\"machine_or_not\", label_dictionary=corpus.make_label_dictionary())\n",
    "\n",
    "# 3. initialize the text classifier trainer with your corpus\n",
    "trainer = ModelTrainer(tars, corpus)\n",
    "\n",
    "# 4. train model\n",
    "trainer.train(base_path='resources/taggers/machine_or_not', # path to store the model artifacts\n",
    "              learning_rate=1e-4, # use very small learning rate\n",
    "              mini_batch_size=1, # small mini-batch size since corpus is tiny\n",
    "              max_epochs=2, # terminate after 10 epochs\n",
    "              train_with_dev=True,\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py37histdict)",
   "language": "python",
   "name": "py37histdict"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
